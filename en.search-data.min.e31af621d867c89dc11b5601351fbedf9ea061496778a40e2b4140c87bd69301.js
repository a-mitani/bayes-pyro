'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href','section'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/docs/bayes_learning_basic/','title':"Bayes Learning Basic",'section':"Docs",'content':" MathJax.Hub.Config({ tex2jax: { inlineMath: [['$', '$'] ], displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ] } });  ベイズ学習の枠組み #  ■ ベイズ学習は確率分布を学習する #  　ベイズ学習は、「事象（データ）$\\mathcal{D}$が観測された」という条件のもとでの未知の変数$\\mathbf{w}$の確率分布、すなわち事後確率分布$p(\\mathbf{w}|\\mathcal{D})$を推論する作業になります。一般的にベイズ学習は以下の２つのStepで行っていくといえます。\n 確率モデル（生成モデル）の構築：対象とする事象がどのような確率過程を経て生成されたのかをモデル化する。 推論：確率モデルと観測されたデータをもとに事後確率を求める。  それぞれのステップについて少し詳しく見ていきましょう。\n▼ Step1：確率モデル（生成モデル）の構築 #  　まず、着目する事象が確率的なプロセス\u0008から発生するものだという仮定を置き、そのプロセスをモデル化することから始めます。確率的な事象を確率変数によって定義し、確率変数の組み合わせで事象を表現していきます。このようなモデルを生成モデルと呼びます。また事象の確率プロセスがモデル化できるとそれはすなわち確率変数間の同時確率分布を定式化することになります。\n例：赤玉白玉問題 #  　赤玉と白玉が入っている袋があり、そこに入っている赤玉と白玉の数の割合$\\Theta$は未知とします。そこでこの袋から無作為に玉を取り出した結果$\\mathcal{D}$をもとに$\\Theta$を推測したいという課題を考えます。\n　この時ベイズ学習では$\\Theta$自体を確率変数と考え、観測データ$\\mathcal{D}$が得られた時の事後確率分布$p(\\Theta | \\mathcal{D})$を推論することになりますが、袋から取り出した時の色が決まる過程はどのようにモデル化できるでしょうか？\n　この問題の場合、下図のように①玉の割合は確率分布$p(\\Theta)$に従って確率的に決まり②$\\Theta$の実現値$\\theta$に準じて取り出す玉の色が確率的に決まるというようにモデル化することになります。\n  また同時確率は同時確率と条件付き確率の定義から $$ p(\\mathcal{D}, \\Theta)=p(\\mathcal{D}| \\Theta)p(\\Theta) $$ と書けることがわかります。\n▼ Step2：推論 #  Step1で確率モデルが構築できたら、そのモデルと観測データから未知のパラメータの確率分布を推論します。これはすなわち冒頭での話のとおり、観測データ$\\mathcal{D}$を得た条件下で未知のパラメータがとる条件付き確率$P(\\mathbf{w}|\\mathcal{D})$を推論することに相当します。 ではこの$P(\\mathbf{w}|\\mathcal{D})$はどう計算すれば良いのかを考えていきましょう。条件付き確率の定義から $$P(\\mathbf{w}|\\mathcal{D})=\\frac{P(\\mathbf{w},\\mathcal{D})}{P(\\mathcal{D})}=\\frac{P(\\mathbf{w},\\mathcal{D})}{\\sum_{\\mathbf{w}} P(\\mathbf{w},\\mathcal{D})}$$ と書き換えられます。 分子の同時確率はStep1の確率モデルの構築ができた時点で定式化されており求めることができるし、分母は未知のパラメータの取りえる値全てに関して同時確率を足し合わす（周辺化する）ことで求められます。\nつまりこの式は、どのような確率モデルの例であっても、同時確率とその未知のパラメータに対する周辺分布を計算することで事後分布$P(W|D)$を推論可能であるということを示していることになります。\n実際の複雑な確率モデルを扱う場合、周辺確率を求めるのに非常にコストがかかるためサンプリングや変分法と呼ばれる近似手法によって事後分布を計算するケースが多いですが、おおもとのベイズ学習の発想は「同時確率とその未知のパラメータに対する周辺分布から事後分布を計算する」ということにあることは覚えておいた方が良いでしょう。\n■ 推論の具体例 #  ここでは手で計算できるレベルの非常に単純なモデルを例に、実際に同時確率とその周辺確率から実際にベイズ推論を行ってみたいと思います。\n例：箱の中のボールの数の推論\nある箱の中にボールが３つ入っている。ボールの色は赤か白のどちらかだが、どの色が何個入っているかはわからない。ここで箱の中からランダムに１つボールを取り出しそのボールの色を確認後箱の中に戻すという操作を行う。 【ケースA】１回の試行で「白」が出た場合 【ケースB】３回の試行で「白→赤→白」が出た場合 の２つの場合で箱の中の白ボールの数がどのように推論できるかを見ていこう。\n【ケースA】１回の試行で「白」が出た場合 #  上のように、確率モデルの構築→推論とステップを踏んで進めていこう。\n確率モデルの構築 #  この場合の事象は下図のようなグラフィカルモデルで表せる。ここで$W={0, 1, 2, 3}$は白玉の数を示す確率変数で、$W$の値により試行時に取り出される玉の色$X={r, w}$の確率が決まるというモデルになっている。\n  また、簡単な確率の考察からそれぞれの確率は下表のようになる。ここで箱の中の玉の数は何の情報もないため等確率で発生するものとして$P_0(W)=1/4$、ここで$W={0,1, 2, 3}$としている。この$P_0(W)$を事前確率という。\n  推論 #  「１回の試行で白ボールを取り出した」というデータが確定したもとでの白ボールの数を推論したいので、求めたいのは事後確率$P(W|X_1=w)$であり、条件付き確率の定義から $$P(W|X_1=w)=\\frac{P(W,X_1=w)}{P(X_1=w)}=\\frac{P(W,X_1=w)}{\\sum_W{P(W, X_1=w)}}\\tag{1}$$ と書ける。上記の最左辺の分子と分母はこれまでの情報で計算できることがわかると思う。それぞれ求めていってみよう。 分子の同時確率は$P(W, X_1)=P(X_1|W)P(W)$であり、$P(W)_0=P(W)$とすると、 上の表から以下のように計算できる。 $$\\begin{cases}P(W=0, X_1=w) \u0026amp;= P(X_1=w|W=0)P_0(W=0)= 0 \\cdot \\frac{1}{4} = 0 \\\\ P(W=1, X_1=w) \u0026amp;= P(X_1=w|W=1)P_0(W=1)= \\frac{1}{3} \\cdot \\frac{1}{4} = \\frac{1}{12} \\\\ P(W=2, X_1=w) \u0026amp;= P(X_1=w|W=2)P_0(W=2)= \\frac{2}{3} \\cdot \\frac{1}{4} = \\frac{1}{6} \\\\ P(W=3, X_1=w) \u0026amp;= P(X_1=w|W=3)P_0(W=3)= 1 \\cdot \\frac{1}{4} = \\frac{1}{4} \\end{cases}$$\nまた(1)式の分母である周辺確率は $$P(X_1=w)=\\sum_{W}P(W, X_1=w) = 0+ \\frac{1}{12} + \\frac{1}{6} + \\frac{1}{4} = \\frac{1}{2}$$ となり、同様に$P(X_1=w)=\\frac{1}{2}$となる。\n(1)式にこれらの結果を代入すると $$\\begin{cases}P(W=0|X_1=w) \u0026amp;= 0 / \\frac{1}{2} = 0\\\\ P(W=1|X_1=w) \u0026amp;= \\frac{1}{12} / \\frac{1}{2} =\\frac{1}{6}\\\\ P(W=2|X_1=w) \u0026amp;= \\frac{1}{6} / \\frac{1}{2} =\\frac{1}{3}\\\\ P(W=3|X_1=w) \u0026amp;= \\frac{1}{4} / \\frac{1}{2} =\\frac{1}{2}\\\\ \\end{cases}$$ となり、１回目に白ボールが出た場合、確率的には箱の中のボールは全部白の可能性が一番高いと推論できることを示している。\n【ケースB】３回の試行で「白→赤→白」が出た場合 #  ケースAと同様の考察を繰り返すと良いです。 要点は、ボールを試行の度に箱に戻すため、Wが決定された状態では、各試行間は独立なので $$P(X_1,X_2,X_3)=P(X_1)P(X_2)P(X_3)$$ となることを利用することにあります。ここで実際の計算は練習問題としておきます。\n"});index.add({'id':1,'href':'/docs/mle_map/','title':"MAP推定と最尤推定",'section':"Docs",'content':" MathJax.Hub.Config({ tex2jax: { inlineMath: [['$', '$'] ], displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ] } });  MAP推定と最尤推定 #  前節までで変分近似を用いてベイズ推論を行ってきました。ベイズ推論は観測出来ない潜在パラメータを確率変数と捉え、ベイズの定理を利用して観測データ$\\mathbf{X}$からそのパラメータの確率分布を推定するものでした。つまり潜在パラメータの確率変数を$\\Theta$とすると下記の関係性を用いて事後分布$p(\\Theta|\\mathbf{X})$を求めることがベイズ推定です。 $$ p(\\Theta|\\mathbf{X}) = \\frac{p(\\mathbf{X}|\\Theta)p(\\Theta)}{p(\\mathbf{X})}\\tag{1} $$\n一方でわざわざ確率分布まで求めなくても、確率分布の最も頻度が高くなる一点を簡易的に求めれば事足りる場合も多々あります。そのような手法としてMAP推定や最尤推定と呼ばれる手法があります。本節ではこれらを紹介したうえでPyroでの計算方法を紹介します。\n※ 以下のコードの全体は Githubリポジトリに置いています。\n■MAP推定 #  MAP推定のMAPはmaximum a posterioriの略であり、日本語に訳すと最大事後確率推定と呼ばれます。その名のとおり観測データに対して事後分布$p(\\Theta|\\mathbf{X})$が最大となるパラメータ値を推定する、つまり、 $$ \\theta_{MAP} = \\underset{\\theta}{\\operatorname{argmax}}~p(\\Theta=\\theta|\\mathbf{X})=\\underset{\\theta}{\\operatorname{argmax}}~p(\\mathbf{X}|\\Theta=\\theta)p(\\theta)\\tag{2} $$ となる$\\theta_{MAP}$を求める作業になります。ここで２つ目の等式は(1)式の関係性から容易に導けるでしょう。\nさて、これまで変分推論では事後確率に近しいと想定される近似関数$q(\\theta)$を用意し、その近似関数の形が本来求めたい事後確率分布に近づくように近似関数のパラメータを最適化しました。その変分推論の枠組みに当てはめたとき、(2)式は近似関数$q(\\theta)$をデルタ関数$\\delta(\\theta-\\theta_{MAP})$と仮定して変分推論することとして解釈が可能です。\nここでデルタ関数$\\delta(\\theta-\\theta_{MAP})$は$\\theta=\\theta_{MAP}$で∞になり、それ以外の$\\theta$ではゼロをとる無限に尖った関数であり$\\int\\delta(\\theta-\\theta_{MAP})d\\theta=1$となります。\n以上のとおりMAP推定をデルタ関数を近似関数とした変分推論と解釈できるならPyroでもguide関数にデルタ関数を指定してあげれることでMAP推定を行うことができます。実際に前節の赤玉白玉の混合比率を例にPyroでMAP推定してみましょう。\n試行データ生成 #  試行結果データを生成するコードは前節と全く同様です。\n# 試行データ作成（前節と同一コード） def create_data(red_num, white_num): red = torch.tensor(1.0) white = torch.tensor(0.0) data = [] for _ in range(red_num): data.append(red) for _ in range(white_num): data.append(white) random.shuffle(data) data = torch.tensor(data) return data data = create_data(6, 4) 最適化ヘルパー関数を定義 #  後ほど最尤推定でも再利用できるように最適化の一連の処理を関数化します。\n# 最適化計算用のヘルパー関数 #　引数として指定されたmodelの関数とguide関数を用いてELBOの最大化を行う def optimize_param(model_fn, guide_fn): # グローバル変数として保存されているパラメータを削除 pyro.clear_param_store() # Optimizerの定義と設定（Adamの利用が推奨されている） adam_params = {\u0026#34;lr\u0026#34;: 0.001, \u0026#34;betas\u0026#34;: (0.95, 0.999)} optimizer = Adam(adam_params) # 推論アルゴリズムとLoss値を定義 # ここでは組み込みのELBOの符号反転をLoss値とする`Trace_ELBO()`を利用しています。 svi = SVI(model_fn, guide_fn, optimizer, loss=Trace_ELBO()) # 最適化の逐次計算 # ここではAdamで勾配降下を1000回繰り返すことになる。 n_steps = 1000 losses = [] for step in range(n_steps): loss = svi.step(data) losses.append(loss) if step % 100 == 0: print(\u0026#39;#\u0026#39;, end=\u0026#39;\u0026#39;) plt.plot(losses) plt.show() 確率モデルと変分関数 #  上述のようにMAP推定は変分推論の枠組みで変分関数としてデルタ関数を仮定するものというお話をしました。そのため確率モデルは前節と全く同じでよく、また変分関数を規定するguide関数はデルタ分布を用います。\n# 確率モデルの定義 def model(data): # 事前確率分布は比率0.5に穏やかなピークを持つ関数を仮定する。 alpha0 = torch.tensor(2.0) beta0 = torch.tensor(2.0) f = pyro.sample(\u0026#34;Theta\u0026#34;, dist.Beta(alpha0, beta0)) # 観測データのプレート定義 with pyro.plate(\u0026#39;observation\u0026#39;): pyro.sample(\u0026#39;X\u0026#39;, dist.Bernoulli(f), obs=data) # MAP推定や最終推定は変分関数としてデルタ関数を仮定する。 def guide_delta(data): theta_opt = pyro.param(\u0026#34;theta_opt\u0026#34;, torch.tensor(0.5), constraint=constraints.unit_interval) pyro.sample(\u0026#34;Theta\u0026#34;, dist.Delta(theta_opt)) 確率モデルと変分関数が用意できたら、変分関数のパラメータ（今回の場合theta_opt）の最適化を行います。\n#　MAP推定用のmodel関数とguide関数を指定して最適化を実施 optimize_param(model_map, guide_delta) # 最適化後の変分パラメータを取得する theta = pyro.param(\u0026#34;theta_opt\u0026#34;).item() print(\u0026#34;theta_opt = {:.3f}\u0026#34;.format(theta)) ## Output # theta_opt = 0.583 上記の結果、thata_optつまり$\\theta_{MAP}$は0.583となりました。前節で行ったベイズ推定結果の事後確率分布の最頻値とほぼ同じ値が求まったことに注意してください。これはMAP推定が全体の確率分布までは求めないけど確率分布の最頻値をとる潜在パラメータの値を求める推定方法であることを考えると納得がいくでしょう。\nまた、試行データを作成する際に、data = create_data(60, 40)として、合計100回の試行データを作成するとtheta_opt = 0.599となります。これは試行回数が増えれば増えるほど、最初に想定していた事前確率分布よりも試行データのほうが重みが増えて試行データの結果の比に近づいていくことを示しています。\n■最尤推定 #  単に観測データ$\\mathbf{X}$に対する尤度が最大となる$\\theta$を求める、すなわち $$ \\theta_{MLE} = \\underset{\\theta}{\\operatorname{argmax}}~p(\\mathbf{X}|\\Theta=\\theta) $$ となる$\\theta_{MLE}$を求めるのが最尤推定（Maximum Likelihood Estimation: MLE）です。\nこれは(2)式と見比べると潜在パラメータの事前分布を$p(\\Theta)$を一定値とした（すなわち事前情報がないとした）MAP推定をしていると解釈することができます。\n以上のことからPyroで最尤推定を行うには場合、事前分布を一様分布としてMAP推定を行えばよいことが分かります。確率モデルは下記のように定義することができます。0~1の範囲で一様分布となるdist.Uniform(0.0, 1.0)で事前分布が定義されているのに注意してください。\n# 最尤推定用に確率モデルの定義（ベイズ推定の際と全く同じことに注意） def model_mle(data): # 事前確率分布は一定値（無情報）として一様分布を指定する f = pyro.sample(\u0026#34;Theta\u0026#34;, dist.Uniform(0.0, 1.0)) # 観測データのプレート定義 with pyro.plate(\u0026#39;observation\u0026#39;): pyro.sample(\u0026#39;X\u0026#39;, dist.Bernoulli(f), obs=data) 上記の確率モデル関数を用いて最適化を以下のように行うことができます。\n#　MAP推定用のmodel関数とguide関数を指定して最適化を実施 optimize_param(model_mle, guide_delta) # 最適化後の変分パラメータを取得する theta = pyro.param(\u0026#34;theta_opt\u0026#34;).item() print(\u0026#34;theta_opt = {:.3f}\u0026#34;.format(theta)) ## Output theta_opt = 0.600 thata_optつまり$\\theta_{MAP}S$は0.600となりました。\nちなみにdata = create_data(3, 2)というように試行回数を幾ら減らしたデータを用いてもtheta_opt=0.600という結果は変わりません。これは最尤推定では例えば比率が半分である可能性が高いといったような事前情報を導入していないため、試行データだけをもとに混合比率を推定したことに起因します。その結果「赤玉と白玉がそれぞれ3回と2回取り出された」という結果に過剰適合（Overfitting）した結果になります。\n"});index.add({'id':2,'href':'/docs/pyro_vi/','title':"Pyroでの変分推論",'section':"Docs",'content':" MathJax.Hub.Config({ tex2jax: { inlineMath: [['$', '$'] ], displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ] } });  Pyroでの変分推論 #  前節で変分近似は、\n 対象の事象の発生過程を確率モデルとしてモデリングする。 推定したいパラメータが従う事後確率分布の近似関数（変分関数）を仮定する。 変分関数と真の事後関数のKLダイバージェンスを最小化する（＝ELBOを最大化する）。  という手順で行うことを説明しました。この節ではPyroを用いて変分推論を具体的に行っていく手順を見ていきます。Pyroでも上の手順をたどっていくことになります。以下の簡単な例を用いてその手順を１つずつ見ていくことにします。\n例：袋の中のボールの比率の推論\n赤玉と白玉が入っている中身が見えない袋があります。袋の中の赤玉と白玉の数は同数入っている（混合比率=0.5）という事前情報がありますが、実際のところはわかっていません。そこで袋の中からランダムに１つを取り出しそのボールの色を確認後、箱の中に戻すという操作を複数回行います。 この時、10回の試行で赤が６回、白が４回が出た場合、玉の混合比率についてどういう推論が可能でしょうか？ベイズ推論の枠組みに従い混合比率の確率分布をPyroを用いて推論していくことにします。\n※ 以下のコードの全体は Githubリポジトリに置いています。\n試行データ #  ここでまず上記例の試行結果のデータを作っておきます。\n# 試行データ作成 def create_data(red_num, white_num): red = torch.tensor(1.0) white = torch.tensor(0.0) data = [] for _ in range(red_num): data.append(red) for _ in range(white_num): data.append(white) random.shuffle(data) data = torch.tensor(data) return data data = create_data(6, 4) 確率モデルの構築 #  混合比率の推論に向けて、まず最初に今回の事象が発生する確率モデルを構築します。\n$i$回目の試行で取り出される玉の色を表す確率変数を$X_i \\in \\lbrace\\text{赤, 白}\\rbrace$とします。例えば混合率（今回は赤玉の比率）を$\\theta$とすると、$\\theta$に応じて$X_i$の実現値が決まると考えられるでしょう。ベイズ機械学習ではこの混合比率$\\theta$も確率的に決まる値であり確率変数$\\Theta$の実現値と考えます。つまり取り出される玉の色は以下の過程で決まるとモデル化します。1\n 混合率の実現値$\\theta$が、事前確率分布$p(\\Theta)$に従って決まる。 混合率が$\\theta$と決まった条件下で、$\\theta$に応じて確率$p(X_i|\\Theta=\\theta)$で玉の色が決まる。  この確率モデルをグラフィカルモデルで記述すると以下の図のようになります。今回の試行は混合率が$\\Theta=\\theta$と決まった条件下で各試行間は独立の関係（条件付き独立）となっています。そこで「プレート表現」を使って$N$回の試行を１つにまとめて表現しています。また玉の色は観測されるもので事後確率を考える上での「条件」となるので変数Xに相当するノードが塗り潰されています2。\n  またこの時、試行回数$N$とした時の同時確率分布は以下のように書けます。ここで$x_i$は$i$回目での思考の玉の色の実現値を示しています。 $$p(\\mathbf{X}=\\mathbf{x}, \\Theta=\\theta)=\\prod_{i=1}^{N} p(X_i=x_i|\\Theta=\\theta)~p(\\Theta=\\theta)$$\nさて、上記ステップ2.の取り出される色の確率分布は比率$\\theta$をパラメータとしたベルヌーイ分布と仮定するのが自然でしょう。つまり $$p(X_i|\\Theta=\\theta)=\\operatorname{Bern}(X_i, \\theta)$$\nと仮定します。 また今回の例の場合、袋の中には赤玉と白玉同数入っているという事前情報があるのでそれをモデルに取り込むために、比率0.5に穏やかなピークをもつベータ分布 $$p(\\Theta)=\\operatorname{Beta}(\\Theta|\\alpha = 2, \\beta = 2)$$ と仮定します3。\nこの確率モデルをPyroで記述してみます。前節で述べたとおりPyroでは確率モデルを確率プリミティブを組み合わせた関数の形で記述します。今回のモデルは以下の様に実装することができます。\n# 確率モデルの定義 def model(data): # 事前確率分布は比率0.5に穏やかなピークを持つ関数を仮定する。 alpha0 = torch.tensor(2.0) beta0 = torch.tensor(2.0) f = pyro.sample(\u0026#34;Theta\u0026#34;, dist.Beta(alpha0, beta0)) # 観測データのプレート定義 with pyro.plate(\u0026#39;observation\u0026#39;): pyro.sample(\u0026#39;X\u0026#39;, dist.Bernoulli(f), obs=data) Pyroでは条件付き独立な関係の確率変数を,グラフィカルモデルと同様にplateとしてまとめる機能を持っており、8,9行目ではそれを利用してモデル化しているのに注意してください。\n変分関数を仮定 #  今回、我々は玉を取り出した結果をもとに玉の混合比率の確率分布$p(\\Theta|X)$を求めようとしています。変分近似ではこの未知の分布をなんらかパラメータを用いて簡単に記述できる分布（変分関数）を仮定してそのパラメータを推定するのでした。ここでは変分関数としてベルヌーイ分布の共役事前分布であるベータ分布を採用し、ベータ分布のパラメータ$\\alpha, \\beta$を推定する問題に帰着させます。\nPyroでは変分関数の定義もモデルの定義と同様に確率プリミティブを組み合わせた関数の形で記述します。Pyroではこの変分関数を定義する関数をguideと呼びます。\ndef guide(data): # 変分パラメータαとβを定義する。 # 初期値は共に10としている。 # また、ベータ分布においてこれらのパラメータは正の値なので`constraints.positive`を指定。 alpha_q = pyro.param(\u0026#34;alpha_q\u0026#34;, torch.tensor(10.0), constraint=constraints.positive) beta_q = pyro.param(\u0026#34;beta_q\u0026#34;, torch.tensor(10.0), constraint=constraints.positive) # 最適化されたパラメータのベータ分布から混合率Θをサンプリングする pyro.sample(\u0026#34;Theta\u0026#34;, dist.Beta(alpha_q, beta_q)) guideを定義する際、以下の点に注意する必要があります。\n guide関数の引数はmodel関数を定義した際の引数と同一であること。 学習対象である変分パラメータ（ここでは$\\alpha, \\beta$）をpyro.paramを用いて定義します。これは後にELBOの各パラメータの偏微分値を求めるために、requires_gradフラグをTrueにセットしたtorch.tensor型の変数として各変分パラメータを定義していることに相当します。  またここではベータ分布において$\\alpha, \\beta$は正の値のためconstraint=constraints.positiveとして最適化過程で取りえる値に制約を加えています。\n最適化 #  変分関数が定義できたので、その中で変分パラメータとして定義したalpha_qとalpha_qをELBOが最大化するように最適化計算を行います。具体的には以下のコードのように実装します。\n# グローバル変数として保存されているパラメータを削除 pyro.clear_param_store() # Optimizerの定義と設定（Adamの利用が推奨されている） adam_params = {\u0026#34;lr\u0026#34;: 0.002, \u0026#34;betas\u0026#34;: (0.95, 0.999)} optimizer = Adam(adam_params) # 推論アルゴリズムとLoss値を定義 # ここでは組み込みのELBOの符号反転をLoss値とする`Trace_ELBO()`を利用しています。 svi = SVI(model, guide, optimizer, loss=Trace_ELBO()) # 最適化の逐次計算 # ここではAdamで勾配降下を1000回繰り返すことになる。 n_steps = 1000 losses = [] for step in range(n_steps): loss = svi.step(data) losses.append(loss) if step % 100 == 0: print(\u0026#39;#\u0026#39;, end=\u0026#39;\u0026#39;) plt.plot(losses) ここで、最適化を行う前に、pyro.clear_param_store()を実行しています。これはPyroではグローバル変数として各変分パラメータを保持しているため、それを消す処理を行っています。 またこのコードでは、svi.step()はLoss値（ELBOの符号逆転値）が返却されるので、Lossの変化をプロットしています。結果は以下の図のようになります。SVI(Stochastic Variational Inference)は確率的勾配降下法(SGD)と同様に計算速度を上げるためにミニバッチで勾配計算を行う4ためLossがランダムに振動していますが、1000回イタレーションを繰り返すと、ELBOが小さいところで落ち着いているのが見てとれます。\n  この最適化後の変分パラメータは以下のコードのようにpyro.paramで取得できます。\n# 最適化後の変分パラメータを取得する alpha_q = pyro.param(\u0026#34;alpha_q\u0026#34;).item() beta_q = pyro.param(\u0026#34;beta_q\u0026#34;).item() print(\u0026#34;alpha_q = {:.2f}, beta_q = {:.2f}\u0026#34;.format(alpha_q, beta_q)) ## Output #alpha_q = 10.55, beta_q = 7.80 我々は混合分布の事後確率分布をベータ分布と仮定していましたから、上記のパラメータを用いて事後確率分布の様子をプロットして確認してみましょう。\n# 得られたパラメータを用いて事後確率分布をプロット x_range = np.arange(0.0, 1.0, 0.01) estimated_dist = dist.Beta(alpha_q, beta_q) y = [estimated_dist.log_prob(torch.tensor([x])).exp() for x in x_range] plt.plot(x_range, y) 得られるグラフは下図のようになります。事後分布$p(\\Theta|X)$は0.6付近が最も大きくなっており、これは10回の試行で赤が6回出た観測事象と辻褄が合っているのがわかります。ただし10回の観測ではまだ混合比率に曖昧性があり、確率分布の裾野が比較的広い確率分布となります。\n  より具体的に今回推論された確率分布の最頻値を求めてみましょう。 計算結果は以下のようになります。 ここで、最頻値0.584となっており、観測結果の0.6より小さくなっているのに注意してください。これは事前確率として0.5をピークに持つ関数を設定していることにより起きています。観測だけを信じると0.6ですが、試行回数が10回程度であればその結果だけを信じて取り込むよりも事前情報の0.5もある程度加味された事後分布になっているという状況です。\n# 最頻値を計算 mode = (alpha_q - 1) / (alpha_q + beta_q - 2) print(\u0026#34;mode = {:.3f}\u0026#34;.format(mode)) # 平均値を計算 mean = alpha_q / (alpha_q + beta_q) # 標準偏差を計算 factor = beta_q / (alpha_q * (1.0 + alpha_q + beta_q)) std = mean * np.sqrt(factor) print(\u0026#34;infered ratio = {:.3f} +- {:.3f}\u0026#34;.format(mean, std)) ## Output # mode = 0.584 # infered ratio = 0.575 +- 0.112 さらに観測回数を増やして1000回の試行でそのうち赤が600回、白が400回取り出された場合はどのような混合比率の事後分布になるでしょうか？ 試行データ作成時にdata = create_data(600, 400)としてデータを作成して同様の推論を行ってみます。 すると結果の事後分布は下記のような形となり、10回の時よりも混合比率が0.6である確信が強まり、確率分布の裾野が10回の思考の場合よりも狭まっているのがわかります。\n  以上、Pyroを用いて簡単な例での変分推定のやり方を見てきました。今回のコードは Githubに配置していますので参考にしてみてください。\n  この様に観測事象の生成過程を仮定してモデリングする確率過程を生成モデルと呼びます。 \u0026#x21a9;\u0026#xfe0e;\n グラフィカルモデルの詳細は例えば このレビュー論文でわかりやすく解説されているので参照してください。 \u0026#x21a9;\u0026#xfe0e;\n ここで事前分布としてベータ関数を採用のは単に確率変数の定義域が0~1かつ一様分布の確率分布を採用したいという動機であり、後のステップで変分関数としてベータ関数を採用するのとは無関係であることに注意してください。 \u0026#x21a9;\u0026#xfe0e;\n  Variational Inference: A Review for Statisticians \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':3,'href':'/docs/what_is_pyro/','title':"Pyroとは",'section':"Docs",'content':"Pyroとは #   PyroはUber AI labにより開発されている、オープンソースの確率的プログラミング言語(Probablistic Programing Language: PPL)です1。Python上で動作し、Pythonのコードを実装する要領で、確率変数やそれらを組み合わせた独自の確率モデルを構築することを可能にしてくれます。\nまた同時に確率モデルの推論を行うための多くのアルゴリズムが実装されており、本書のメイントピックであるベイズ機械学習（以降、ベイズ学習）を非常にシンプルな形で実装することが可能になります。特に変分推論においては学習時に最大化していく対象であるELBO(Evidence Lower Bound)をユーザーが構築した独自の確率モデルに従って自動で計算する機能を備えており、Pyroを用いると変分推論の実装が非常に容易になります2。このような機能により深層学習とベイズ学習を組み合わせた深層ベイズ学習などの実装も非常に容易になります。\nPyroはそのバックエンドに深層学習フレームワークの Pytorchを利用しているため、Pytorchのもつ自動微分(autograd)機能やGPU計算機能を利用することで高速な学習が可能になっているところに特徴があります。\nPyroのインストール #  ローカル環境へのPyroのインストール #  自身のローカル環境でPyroを利用する場合、まずは、まず Pytorchをインストールする必要があります。Pytorchをインストール後、\npip install pyro-ppl コマンドによりPyroのインストールします。\nGoogle ColabratoryでのPyroのインストール #  以降の本書のサンプルコードは全て Google Colabratory上で動作させることを前提としています。ColabratoryはPytorchは事前にインストールされているため、下記の「!」を冒頭につけたpipコマンドをセル上で動かすだけででPyroをインストールすることが可能です。\n!pip install pyro-ppl 次節以降で、ベイズ学習の基礎とPyroを用いた実装方法を学んでいきます。\n  「プログラミング言語」と名乗ってはいますが、Pythonで動作するライブラリの位置付けなので、確率的プログラミングをするための「フレームワーク」と考えた方がわかりやすいかもしれません。 \u0026#x21a9;\u0026#xfe0e;\n これは言うなれば深層学習においてTensorflowやPytorchがユーザーが独自に構築したニューラルネットワークの損失関数の勾配を自動で計算してくれることに対応していると考えれば、この機能の便利さが容易に想像できます。 \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':4,'href':'/docs/pyro_modeling/','title':"Pyroによる確率モデリング",'section':"Docs",'content':" MathJax.Hub.Config({ tex2jax: { inlineMath: [['$', '$'] ], displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ] } });  Pyroによる確率モデリング #  前節で「Pyroにより確率変数やそれらを組み合わせた確率モデルを容易に扱うことが可能になる」ことを述べました。本節ではもう少し詳しくPyroがどのように確率変数や確率モデルを扱うのかをみていきたいと思います。\nPyroでは大きく２つの構成要素により確率変数や確率モデルを扱います。１つが確率プリミティブ。もう１つが確率モデルのハンドラであるpoutineです。以下でそれぞれ詳しくみていきましょう。\n以降、前節の手順でpyroがインストールされ、以下のimportが実行されている前提で話を進めます。\nimport matplotlib.pyplot as plt import pyro import pyro.distributions as dist from pyro.poutine import trace ■確率プリミティブ #  一般的にベイズ学習において確率モデルは確率的に実現値が変動する「確率変数」の組み合わせで構成されます。そしてPyro上で確率変数を宣言するものが確率プリミティブです。\n確率変数の宣言 #  例えば平均0で標準偏差が1のガウス分布に従う確率変数$X$を考える時、Pyroでは$X$を\nx = pyro.sample(\u0026#34;X\u0026#34;, dist.Normal(0, 1)) print(x) ## Output # tensor(0.0784) のようにpyro.sampleを用いて宣言します。ここで第一引数は確率変数名を宣言しており、後に行う推論などではこの名前を確率変数のIDとして処理を行います（そのために一意に命名する必要があります。）。第二引数は確率変数$X$の従う確率分布を指定しており、今回は正規分布のNormalを用いています。 また、pyro.sample関数は指定された確率分布にしたがって値をサンプリングする関数となっており、python変数であるxにはサンプリングされた実現値が代入されることになります（2行目print文）。\n確率変数$X$から独立同分布(i.i.d)で実現値をサンプリングしたければ、以下のコード例のようにpyro.sample文をforループを回すことで可能です。\nx_list = [] for _ in range(10000): x = pyro.sample(\u0026#34;X\u0026#34;, dist.Normal(0, 1)) x_list.append(x) plt.hist(x_list, bins=20)   plateを用いたサンプリング #  確率変数から多数のサンプリングを行う場合、上記のようにforループを用いてシーケンシャルにサンプリングを行うことは計算効率がよくありません。そこでPyroでは効率よくサンプリングを行うためにpyro.plateというコンテキストマネージャが用意されており、上記のFor文によるサンプリングと同様のことを下記のコードで行うことができます。\nwith pyro.plate(\u0026#34;plate1\u0026#34;, size=10000): samples = pyro.sample(\u0026#34;samples\u0026#34;, dist.Normal(0, 1)) print(\u0026#34;var_type is {}, shape = {}\u0026#34;.format(type(samples), samples.shape)) plt.hist(samples, bins=20) ## Output # var_type is \u0026lt;class \u0026#39;torch.Tensor\u0026#39;\u0026gt;, shape = torch.Size([10000]) 当然ですが出力されるヒストグラムもFor文の結果と同様の形になります。\n  pyro.plateはそのコンテキスト内でサンプルされた事象はお互いに独立であることをPyroに明示的に伝える役割があります。このことは特に推論時の処理時間に非常に大きな影響を与えます。なぜなら独立である場合はサンプリング時に並列処理を行うことができるからです。\n実際に手元の処理時間を比較すると、For文によるサンプリングが0.72秒で、plateを利用した場合は0.003秒と200倍以上の速度差がでました。plateで得られた変数値はサンプル数だけ要素を持った１つのtorch.Tensor型の変数に格納されていることにも注意してください。\n以上のことからそれぞれ独立にサンプルする場合は積極的にpyro.plateを用いることが推奨されます。\n確率モデルの宣言 #  確率モデルは、確率プリミティブの演算の組み合わせで構成されたPython関数として宣言します。\n簡単な確率モデルをPyroで定義する例をみてみましょう。ここでは以下のような例を考えます。\n例:赤玉白玉問題 下図のように、２つの袋$a$および$b$があり、袋$a$には赤玉が2個、白玉が1個入っており、袋$b$には赤玉が1個、白玉が3個入っているものとします。ここで、２つの袋のうち一方の袋を等確率にランダムに選び、その選んだ袋から玉を１つ取り出す試行を行います。\n  ここで「袋が選ばれる」「玉が取り出される」という確率的な過程をそれぞれ確率変数$X$、$Y$とすると上の試行は下記のグラフィカルモデルのように記述出来ます。   この確率モデルは下記のball_modelのようなpython関数として定義することができます。4行目では確率変数$X$の分布をp=0.5のベルヌーイ分布を指定しています。ここで確率変数$X$の実現値が1の場合は袋aを、0の場合は袋bが選ばれたものとします。そして選ばれた袋（確率変数の実現値）に応じて、確率変数$Y$の確率分布がスイッチし、それぞれの袋の中の赤玉と白玉の数に合わせてベルヌーイ分布の確率が指定されています。確率変数$Y$の実現値が1の場合は赤玉を、0の場合は白玉が取り出されたものとします。\nちなみに、このように観測値（今回の場合は取り出した玉の色）がどのような確率過程で生み出されたのかを記述するようなモデルを生成モデルと呼ばれます。\n# x=1: 袋a, x=0: 袋b # y=1: 赤玉, y=0:　白玉 def ball_model(): x = pyro.sample(\u0026#34;X\u0026#34;, dist.Bernoulli(0.5)) if x: y = pyro.sample(\u0026#34;Y\u0026#34;, dist.Bernoulli(2.0/3.0)) else: y = pyro.sample(\u0026#34;Y\u0026#34;, dist.Bernoulli(1.0/4.0)) return y 確率プリミティブの組み合わせで構成されたball_modelの関数もやはり確率的な挙動を示す確率的関数として動作し、下記のコード例のように、関数が呼ばれたらその関数内で定義されたモデルに従って値をサンプリングする動作をします。（もちろんpyro.plateを用いたサンプリングも可能です1。）\nfor _ in range(5): print(ball_model()) ## output # tensor(0.) # tensor(0.) # tensor(1.) # tensor(0.) # tensor(1.) 複雑な確率モデル #  確率モデルをPythonの関数の形で書けることは、今後さらに複雑な確率モデルを考えていく上で非常に便利な特徴です。Pythonの関数と同様に、確率モデルに引数を渡したり、再帰的な確率モデルを構築することも容易ですし、関数同士を組み合わせることも可能です。（下記コード例参照）\ndef geometric(p, t=None): if t is None: t = 0 x = pyro.sample(\u0026#34;x_{}\u0026#34;.format(t), pyro.distributions.Bernoulli(p)) if x.item() == 1: return 0 else: return 1 + geometric(p, t + 1) print(geometric(0.5)) ## output # 0 ■エフェクト・ハンドラ poutine #  ここまでで、確率モデルをPythonの関数として実装し、その確率モデルに従ったサンプリングを行うことができました。ベイズ推論などを行っていく際には、その確率モデルの挙動を記録したり、挙動を修正（e.g.条件付けなど）など確率モデルをハンドリングする必要があります。そのようなハンドリング機能を担うのがpoutineモジュールです。ここではpoutineのモジュールの中でよく利用されるものを紹介します。\n確率モデル挙動の記録 Trace #  ベイズ推論を行う際には実現値を出力するに至るまでに確率モデルの内部の確率変数がどういう値を取ったのかを知りたい場合が多くあります。PyroではTraceオブジェクトが確率モデルをサンプルした際の挙動を記録する役割を担います。Traceオブジェクトは下記コードのようにして取得します。\ntraced_model = poutine.trace(model_fn) # TraceMessengerオブジェクトを取得 trace = traced_model.get_trace() # Traceオブジェクトを取得 1行目で対象とする確率モデルのTraceMessengerオブジェクトをtraced_modelの名前で取得し、2行目のget_traceでサンプリングとそのサンプリング時の確率モデルの内部状態をTraceオブジェクトに記録しています。ここで対象の確率モデル関数が引数を持つ場合はget_traceの引数に指定することで引数に応じたサンプリングを行います。\nTraceオブジェクトは有向グラフの形式で確率モデルのサンプリング状態を記録しており、その有向グラフは確率モデルのインプットとアウトプット、そしてモデル内の確率変数をノードとして持ちます。例として以下のコードようにball_modelの内部状態を出力してみます。 この出力内容を見ると、ball_modelには関数内で明示的に定義した'X', 'Y'に加えて'_INPUT'、'_RETURN'ノードが存在することがわかります。また今回のモデルの実現値は内部のそれぞれの確率変数の実現値（value）が'X'=tensor(0.)、'Y'=tensor(1.)となることでモデルの最終的な出力'_RETURN'の実現値がtensor(1.)となっていることが窺い知ることができます。\ntr = trace(ball_model).get_trace() for tr_items in tr.nodes.items(): print(tr_items) # output # (\u0026#39;_INPUT\u0026#39;, {\u0026#39;name\u0026#39;: \u0026#39;_INPUT\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;args\u0026#39;, \u0026#39;args\u0026#39;: (), \u0026#39;kwargs\u0026#39;: {}}) # (\u0026#39;X\u0026#39;, {\u0026#39;type\u0026#39;: \u0026#39;sample\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;X\u0026#39;, \u0026#39;fn\u0026#39;: Bernoulli(probs: 0.5), \u0026#39;is_observed\u0026#39;: False, \u0026#39;args\u0026#39;: (), \u0026#39;kwargs\u0026#39;: {}, \u0026#39;value\u0026#39;: tensor(0.), \u0026#39;infer\u0026#39;: {}, \u0026#39;scale\u0026#39;: 1.0, \u0026#39;mask\u0026#39;: None, \u0026#39;cond_indep_stack\u0026#39;: (), \u0026#39;done\u0026#39;: True, \u0026#39;stop\u0026#39;: False, \u0026#39;continuation\u0026#39;: None}) # (\u0026#39;Y\u0026#39;, {\u0026#39;type\u0026#39;: \u0026#39;sample\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;Y\u0026#39;, \u0026#39;fn\u0026#39;: Bernoulli(probs: 0.25), \u0026#39;is_observed\u0026#39;: False, \u0026#39;args\u0026#39;: (), \u0026#39;kwargs\u0026#39;: {}, \u0026#39;value\u0026#39;: tensor(1.), \u0026#39;infer\u0026#39;: {}, \u0026#39;scale\u0026#39;: 1.0, \u0026#39;mask\u0026#39;: None, \u0026#39;cond_indep_stack\u0026#39;: (), \u0026#39;done\u0026#39;: True, \u0026#39;stop\u0026#39;: False, \u0026#39;continuation\u0026#39;: None}) # (\u0026#39;_RETURN\u0026#39;, {\u0026#39;name\u0026#39;: \u0026#39;_RETURN\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;return\u0026#39;, \u0026#39;value\u0026#39;: tensor(1.)}) 条件付け condition #  conditionハンドラを用いてモデル内の各確率変数の実現値を固定（条件付け）してサンプリングを行うことが可能になります。条件付けはkeyを確率変数名、valueを固定する実現値としたdictionary型でconditionハンドラに渡します。\nこのconditionハンドラを用いると、例えば、確率モデルの全ての確率変数の実現値を固定した上でサンプリングし、その確率を求めると同時確率を求めらます。以下に、ball_modelにおいて「袋aが選ばれ、赤玉が得られる」場合の同時確率、つまり$p(X=1, Y=1)$を求める例を示します。\nここで、最後のtr.log_prob_sum()はモデル内の各確率変数の対数確率の和を出力する関数です。つまりこの例では $$ ln(p(X=1))+ln(p(Y=1)) $$ を計算してることに注意してください。\nond_dict = {\u0026#34;X\u0026#34;: torch.tensor(1.), \u0026#34;Y\u0026#34;: torch.tensor(1.)} # 袋a=1, 赤玉=1  conditioned_model = condition(ball_model, cond_dict) tr = trace(conditioned_model).get_trace() for tr_items in tr.nodes.items(): print(tr_items) print(\u0026#39;p(X=1, Y=1) =\u0026#39;, tr.log_prob_sum().exp().item()) ## Output # (\u0026#39;_INPUT\u0026#39;, {\u0026#39;name\u0026#39;: \u0026#39;_INPUT\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;args\u0026#39;, \u0026#39;args\u0026#39;: (), \u0026#39;kwargs\u0026#39;: {}}) # (\u0026#39;X\u0026#39;, {\u0026#39;type\u0026#39;: \u0026#39;sample\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;X\u0026#39;, \u0026#39;fn\u0026#39;: Bernoulli(probs: 0.5), \u0026#39;is_observed\u0026#39;: True, \u0026#39;args\u0026#39;: (), \u0026#39;kwargs\u0026#39;: {}, \u0026#39;value\u0026#39;: tensor(1.), \u0026#39;infer\u0026#39;: {}, \u0026#39;scale\u0026#39;: 1.0, \u0026#39;mask\u0026#39;: None, \u0026#39;cond_indep_stack\u0026#39;: (), \u0026#39;done\u0026#39;: True, \u0026#39;stop\u0026#39;: False, \u0026#39;continuation\u0026#39;: None}) # (\u0026#39;Y\u0026#39;, {\u0026#39;type\u0026#39;: \u0026#39;sample\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;Y\u0026#39;, \u0026#39;fn\u0026#39;: Bernoulli(probs: 0.6666666865348816), \u0026#39;is_observed\u0026#39;: True, \u0026#39;args\u0026#39;: (), \u0026#39;kwargs\u0026#39;: {}, \u0026#39;value\u0026#39;: tensor(1.), \u0026#39;infer\u0026#39;: {}, \u0026#39;scale\u0026#39;: 1.0, \u0026#39;mask\u0026#39;: None, \u0026#39;cond_indep_stack\u0026#39;: (), \u0026#39;done\u0026#39;: True, \u0026#39;stop\u0026#39;: False, \u0026#39;continuation\u0026#39;: None}) # (\u0026#39;_RETURN\u0026#39;, {\u0026#39;name\u0026#39;: \u0026#39;_RETURN\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;return\u0026#39;, \u0026#39;value\u0026#39;: tensor(1.)}) # p(X=1, Y=1) = 0.3333333134651184 上記の出力結果から指定された条件付けに基づいてサンプリングされ、また計算された同時確率$p(X=1, Y=1) = 0.333\u0026hellip;$はモデルから解析的に得られる値 $$ p(X=1, Y=1) = p(X=1)P(Y=1) = \\frac{1}{2} * \\frac{2}{3} = \\frac{1}{3} $$ と一致していることがわかります。\n確率変数の隠蔽 block #  blockハンドラを用いると、モデル内の指定された確率変数から隠蔽されます。これは例え以下のコードのようにconditionと組み合わせて条件付き確率（$p(X=1|Y=1$）を求めたい時に使うことができます。\ncond_dict = {\u0026#34;X\u0026#34;: torch.tensor(1.), \u0026#34;Y\u0026#34;: torch.tensor(1.)} # 袋a=1, 赤玉=1  conditioned_model = condition(ball_model, cond_dict) blocked_model = block(conditioned_model, hide=[\u0026#34;X\u0026#34;]) tr = trace(blocked_model).get_trace() for tr_items in tr.nodes.items(): print(tr_items) print(\u0026#39;p(Y=1|X=1) =\u0026#39;, tr.log_prob_sum().exp().item()) # Output # \u0026#39;_INPUT\u0026#39;, {\u0026#39;name\u0026#39;: \u0026#39;_INPUT\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;args\u0026#39;, \u0026#39;args\u0026#39;: (), \u0026#39;kwargs\u0026#39;: {}}) # (\u0026#39;Y\u0026#39;, {\u0026#39;type\u0026#39;: \u0026#39;sample\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;Y\u0026#39;, \u0026#39;fn\u0026#39;: Bernoulli(probs: 0.6666666865348816), \u0026#39;is_observed\u0026#39;: True, \u0026#39;args\u0026#39;: (), \u0026#39;kwargs\u0026#39;: {}, \u0026#39;value\u0026#39;: tensor(1.), \u0026#39;infer\u0026#39;: {}, \u0026#39;scale\u0026#39;: 1.0, \u0026#39;mask\u0026#39;: None, \u0026#39;cond_indep_stack\u0026#39;: (), \u0026#39;done\u0026#39;: True, \u0026#39;stop\u0026#39;: False, \u0026#39;continuation\u0026#39;: None}) # (\u0026#39;_RETURN\u0026#39;, {\u0026#39;name\u0026#39;: \u0026#39;_RETURN\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;return\u0026#39;, \u0026#39;value\u0026#39;: tensor(1.)}) # p(Y=1|X=1) = 0.6666666269302368 Tips\nPyroにおける確率モデルのハンドリングする仕組みとしてpoutineを用いて同時確率や条件付き確率を計算する手法を紹介しました。読者によってはコードが少々回りくどい印象を受けるかもしれません。\n実際のところはpoutineモジュールは、Pyroの推論モジュールから呼ばれる前提で設計されており、ユーザー自身がpoutineを用いて確率モデルをハンドルすることはほとんどありません。\n ■ベイズ学習へ #  ここまででPyroを用いて対象の事象に合わせた確率モデル、いわゆる生成モデルを定義することを行ってきました。ベイズ学習ではこの確率モデルに観測されたデータを組み合わせることで、未知のパラメータを学習・推論することになります。例えば、前述の赤玉白玉問題の場合、取り出された玉の色のデータをもとに袋の中の赤玉の数を推定していくことを行います。\nPyroを用いてベイズ学習を実装していく前に、必要最小限のベイズ学習の知識を復讐していきましょう。\n  plateを用いる場合は、Tensorの演算を行うためmodelにif分岐を使えない制約があるためIF文を用いずに等価なモデルを記述する必要があります。ball_modelの場合の実装例を Gistに載せたので参照ください。 \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':5,'href':'/docs/linear_regression/','title':"ベイズ線形回帰",'section':"Docs",'content':" MathJax.Hub.Config({ tex2jax: { inlineMath: [['$', '$'] ], displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ] } });  ベイズ線形回帰 #  本節では回帰問題をPyroを使ってベイズ機械学習（ここでは変分近似）の枠組みで考えていきます。回帰問題は一般に説明変数$\\mathbf{x}$と説明変数$y$の$N$個のセット、すなわち $$ \\mathcal{D}={(\\mathbf{x}_1, y_1),\\cdots(\\mathbf{x}_i, y_i)\\cdots ,(\\mathbf{x}_N, y_N)} $$ が与えられたとき、それぞれのサンプルに対して $$ y_i = f(\\mathbf{w}, \\mathbf{x}_i, \\epsilon_i)\\tag{1} $$ のように$y_i$を未知のパラメータ$\\mathbf{w}$と説明変数$\\mathbf{x}_i$と観測誤差$\\epsilon_i$の関数で表されると仮定し、パラメータ$\\mathbf{w}$をデータセット$\\mathcal{D}$から推論するタスクになります。\n$\\mathbf{X}=\\lbrace\\mathbf{x}_1,\\cdots, \\mathbf{x}_N\\rbrace$、$\\mathbf{Y}=\\lbrace y_1,\\cdots, y_N\\rbrace$とすると、$\\mathbf{w}$、$\\mathbf{X}$、$\\mathbf{Y}$の同時確率は\n$$ p(\\mathbf{X},\\mathbf{Y},\\mathbf{w})=p(\\mathbf{w})\\prod_{i=1}^{N}p(y_i|\\mathbf{x}_i,\\mathbf{w})p(\\mathbf{x}_i)\\tag{2} $$ と書けることが分かります。ここで各サンプル間は独立であることをを仮定しており積の形で表せることに注意してください。この同時確率はグラフィカルモデルで表すと下図のように書けます。\n  $\\mathbf{X}$と$\\mathbf{Y}$の組みが観測されたときの$\\mathbf{w}$の事後分布は、事後確率の定義と(2)式から以下のように書けることが分かります。 $$ \\begin{align} p(\\mathbf{w}|\\mathbf{X},\\mathbf{Y})\u0026amp; =\\frac{p(\\mathbf{X},\\mathbf{Y},\\mathbf{w})}{p(\\mathbf{X},\\mathbf{Y})}\\newline \u0026amp; =\\frac{p(\\mathbf{w})\\prod_{i=1}^{N}p(y_i|\\mathbf{x}_i,\\mathbf{w})p(\\mathbf{x}_i)}{p(\\mathbf{Y}|\\mathbf{X})p(\\mathbf{X})}\\newline \u0026amp; = \\frac{p(\\mathbf{w})\\prod_{i=1}^{N}p(y_i|\\mathbf{x}_i,\\mathbf{w})}{p(\\mathbf{Y}|\\mathbf{X})}\\tag{3} \\end{align} $$ ここで２行目から３行目はデータサンプル間の独立性から$p(\\mathbf{X})=\\prod_{i}p(\\mathbf{x}_i)$と書けることを利用しています。\nこのパラメータ$\\mathbf{w}$の事後分布をデータから推定するタスクがベイズ回帰です。\n■１次元線形回帰 #  まずは回帰の最も簡単な例として１次元線形回帰を考えていきましょう。この場合(1)式の具体的な関数型として $$ y_i=w_0 + w_1 x_i + \\epsilon_i \\tag{4} $$ と仮定することに相当します。ここで$\\epsilon_i$を平均0、標準偏差$\\sigma$のガウス分布に従う、つまり $$ \\epsilon \\sim \\mathcal{N}(\\epsilon|0, \\sigma) \\tag{5} $$ と仮定すると、(4)、(5)式をまとめることで(2)式の中の$p(y_i|\\mathbf{x}_i,\\mathbf{w})$は具体的に $$ p(y_i|\\mathbf{x}_i,\\mathbf{w})=\\mathcal{N}(y_i|w_0+w_1 x_i, \\sigma)\\tag{5} $$ と書けることが分かります。 ここで観測誤差の広がり度合いを示す$\\sigma$も推定したいパラメータとすると(2)式は $$ p(\\mathbf{X},\\mathbf{Y},w_0,w_1,\\sigma)=p(w_0)p(w_1)p(\\sigma)\\prod_i\\mathcal{N}(y_i|w_0+w_1 x_i, \\sigma)p(x_i)\\tag{6} $$ という具体的な形に書くことができます。またこの同時確率をグラフィカルモデルで記述すれば以下の図のようになります。\n  ここで未知のパラメータ$w_0$、$w_1$、$\\sigma$（以降、これらを潜在変数と呼ぶ）の事後確率分布を求めるのが今回の一次元線形回帰のタスクになります。まずは (6)式の確率モデルをPyroを用いて記述し変分推定を行っていくところをみていきましょう。\nなお以降では下記のコードを実行されている前提で話を進めていきます。\n※プログラムコードの全体は Github上に公開しています。\nimport matplotlib.pyplot as plt import numpy as np import torch from torch.distributions import constraints import pyro import pyro.distributions as dist from pyro.infer import SVI, Trace_ELBO from pyro.infer import Predictive np.random.seed(1) pyro.set_rng_seed(1) また、下記のコードで生成されるToyデータセットを例に進めていきます。\ndef create_linear_data(w0=3.0, w1=2.0, sigma=5.0, size=20): x = np.random.rand(size) * 10.0 y = w0 + w1 * x y = y + np.random.normal(scale=sigma, size=x.shape[0]) return x, y x, y = create_linear_data() train = torch.tensor(np.array([x, y]).T, dtype=torch.float) このコードで生成されるデータは(1)式において$w=2.0$、$b=3.0$とし、観測誤差が標準偏差5.0のガウス分布で発生するとしたデータになります。生成されたデータは以下のグラフのようになります。このToyデータセットをもとにベイズ線形回帰を行っていきましょう。\n  確率モデルの構築 #  (6)式の確率モデルをPyroを用いて関数として定義します。\ndef model(x, y): w0 = pyro.sample(\u0026#34;w0\u0026#34;, dist.Normal(0., 10.)) w1 = pyro.sample(\u0026#34;w1\u0026#34;, dist.Normal(0., 10.)) sigma = pyro.sample(\u0026#34;sigma\u0026#34;, dist.Uniform(0., 10.)) mean = w0 + w1 * x with pyro.plate(\u0026#34;data\u0026#34;, len(x)): pyro.sample(\u0026#34;obs\u0026#34;, dist.Normal(mean, sigma), obs=y) ここで、w0とw1の事前確率分布は平均0で標準偏差10の正規分布、sigmaは0~10の値をとる一様分布としていることになります。\n変分関数を指定 #  次に変分関数を定義します。こちらも Pyroでの変分推論の節と同様、guide関数で実装することになります。今回は以下のコードのように実装します。\ndef guide(x, y): w0_loc = pyro.param(\u0026#39;w0_loc\u0026#39;, torch.tensor(0.)) w0_scale = pyro.param(\u0026#39;w0_scale\u0026#39;, torch.tensor(1.), constraint=constraints.positive) w1_loc = pyro.param(\u0026#39;w1_loc\u0026#39;, torch.tensor(0.0)) w1_scale = pyro.param(\u0026#39;w1_scale\u0026#39;, torch.tensor(1.0), constraint=constraints.positive) sigma_loc = pyro.param(\u0026#39;sigma_loc\u0026#39;, torch.tensor(1.), constraint=constraints.positive) sigma_scale = pyro.param(\u0026#39;sigma_scale\u0026#39;, torch.tensor(0.5), constraint=constraints.positive) w0 = pyro.sample(\u0026#34;w0\u0026#34;, dist.Normal(w0_loc, w0_scale)) w1 = pyro.sample(\u0026#34;w1\u0026#34;, dist.Normal(w1_loc, w1_scale)) sigma = pyro.sample(\u0026#34;sigma\u0026#34;, dist.Normal(sigma_loc, sigma_scale)) 上記コードでは、今回推定したいパラメータ（潜在変数）$w_0$、$w_1$、$\\sigma$の事後確率分布をそれぞれ正規分布と仮定していることになります。正規分布を特徴付けるパラメータは平均locと標準偏差scaleのため、以降の推論パートではELBO最大にするように潜在変数毎のこれら２つのパラメータを最適化することになります。そのため潜在変数それぞれの平均と標準偏差をpyro.paramを用いて定義することにより、これらが最適化対象の変数であるということをPyroに伝えます。また標準偏差は正の値をとるためconstraint=constraints.positiveとして正値のみをとるように制約条件を課していることに注意してください。また、繰り返しですがguide関数の引数はmodel関数と同一でないといけないことに注意してください。\n推論 #  確率モデルと変分関数を定義したら、あとは推論を行っていきます。こちらも 変分推論を試すと同様であることがわかるでしょう。\noptimizer = pyro.optim.Adam({\u0026#34;lr\u0026#34;: .1}) svi = SVI(model, guide, optimizer, loss=Trace_ELBO()) x, y = train[:, 0], train[:, 1] pyro.clear_param_store() num_iters = 5000 iter_nums = [] losses = [] for i in range(num_iters): loss = svi.step(x, y) iter_nums.append(i + 1) losses.append(loss) if i % (num_iters / 10) == 0: print(\u0026#34;Elbo loss: {}\u0026#34;.format(loss)) plt.plot(iter_nums, losses) plt.xscale(\u0026#34;log\u0026#34;) plt.show() ## Output # Elbo loss: 929.2532387375832 # Elbo loss: 62.93969136476517 # Elbo loss: 63.404844522476196 # Elbo loss: 64.26783436536789 # Elbo loss: 64.90034347772598 # Elbo loss: 63.357214510440826 # Elbo loss: 62.72878021001816 # Elbo loss: 73.45997166633606 # Elbo loss: 63.51271438598633 # Elbo loss: 63.471219420433044   出力されるプロットを確認すれば、ELBO（のマイナス値）は十分収束しているのが分かります。 学習モデルの確認 #  学習結果のパラメータの内容はpyro.get_param_store()から参照可能です。最適化されたパラメータを出力してみましょう。\nfor name, value in pyro.get_param_store().items(): print(\u0026#34;{} = {:.3f}\u0026#34;.format(name, pyro.param(name).item())) ### Output # w0_loc = 2.959 # w0_scale = 0.840 # w1_loc = 1.842 # w1_scale = 0.182 # sigma_loc = 4.156 # sigma_scale = 0.614 これらのパラメータから潜在変数の事後確率分布をプロットしてみましょう。\nx_range = np.arange(0.0, 6.0, 0.01) latent_vars = [\u0026#34;w0\u0026#34;, \u0026#34;w1\u0026#34;, \u0026#34;sigma\u0026#34;] for latent_var in latent_vars: param_loc = latent_var + \u0026#34;_loc\u0026#34; param_scale = latent_var + \u0026#34;_scale\u0026#34; inferred_dist = dist.Normal(pyro.param(param_loc).item(), pyro.param(param_scale).item()) inferred_y = [inferred_dist.log_prob(torch.tensor([x])).exp() for x in x_range] plt.plot(x_range, inferred_y) plt.show()   学習の結果、潜在変数の事後分布はトイデータを作成した正解の値に近いところを中心にそれぞれ分布しているのが見て取れます。 また、潜在変数の事後分布の平均値で回帰直線を引いてみると以下のようになります。\nplt.scatter(x, y) x_test = np.arange(0, 10, 0.1) w0_loc = pyro.param(\u0026#34;w0_loc\u0026#34;).item() w1_loc = pyro.param(\u0026#34;w1_loc\u0026#34;).item() y_test = w0_loc + w1_loc * x_test plt.plot(x_test, y_test) plt.show()   サンプルに沿った回帰直線が引けて学習が正常に動いているのが見て取れます。 Hint\n今回は変分関数としてガウス分布を指定しているため、事後分布の平均値はすなわち事後分布の最大点と等しくなります。つまり上の図はMAP推定をした場合の回帰直線を意味していることになります。\n また学習した潜在変数の事後分布からサンプリングを行うことも可能です。サンプリングには下記のコードのようにpyro.infer.Predictiveのクラスを利用すると便利です。\nX_range = torch.tensor(np.linspace(0, 10, 50)) predictive = Predictive(model=model, guide=guide, num_samples=1000, return_sites=[\u0026#34;w0\u0026#34;, \u0026#34;w1\u0026#34;, \u0026#34;obs\u0026#34;]) predict_samples = predictive.get_samples(X_range, None) このコードではX_range変数に格納された$x=0\\sim 10$の範囲の50の点それぞれに対して、指定されたmodelとguideの関数に従って1000回サンプリングを行うことをしています。またサンプリングされる量はreturn_sitesで指定された確率変数がサンプリングされます。\nさて、これを利用して回帰直線の90%信頼区間をプロットしてみます。\nsampled_vals = predict_samples[\u0026#34;w0\u0026#34;] + predict_samples[\u0026#34;w1\u0026#34;] * X_range mean_vals = sampled_vals.mean(0) percent05_vals = sampled_vals.kthvalue(int(sampled_vals.shape[0] * 0.05), dim=0)[0] percent95_vals = sampled_vals.kthvalue(int(sampled_vals.shape[0] * 0.95), dim=0)[0] plt.scatter(x, y) plt.plot(X_range, mean_vals, color=\u0026#39;r\u0026#39;) plt.fill_between(X_range, percent05_vals, percent95_vals, color=\u0026#39;r\u0026#39;, alpha=0.2) 2行目でサンプリングされた$w_0$,$w_1$をもとに目的変数$y$を計算しています。４と５行目で、これらサンプリングされた点から5%,95%パーセンタイル値を取得。結果をプロットしています。\n  90%信頼区間の領域中に多くの観測値が入っていないのに注意してください。これは上図が回帰線の信頼区間をプロットしており観測誤差を考慮にいれていないことに起因します。\n上図のような信頼区間の回帰線に観測誤差$\\sigma$が加わる「観測値」はどの範囲に広がるのかを調べてみます。ここでは「観測値」の90%信頼区間をプロットしてみましょう。model関数内で観測誤差$\\sigma$を含んだ観測値はobs変数として定義したのを思い出すと、obs変数のサンプリング値を利用すると目的の信頼区間が得られることが分かります。上記の回帰直線の信頼区間をプロットしたのと同様に以下のコードで観測値90%信頼区間がプロットできます。\n# 観測誤差も考慮したの90%信頼区間をプロット sampled_vals = predict_samples[\u0026#34;obs\u0026#34;] mean_vals = sampled_vals.mean(0) percent05_vals = sampled_vals.kthvalue(int(sampled_vals.shape[0] * 0.05), dim=0)[0] percent95_vals = sampled_vals.kthvalue(int(sampled_vals.shape[0] * 0.95), dim=0)[0] plt.scatter(x, y) plt.plot(X_range, mean_vals, color=\u0026#39;g\u0026#39;) plt.fill_between(X_range, percent05_vals, percent95_vals, color=\u0026#39;g\u0026#39;, alpha=0.2)   多くの観測値が90%信頼区間に入っており、今回ベイズ学習した回帰モデルでデータセットが上手く表現出来ていることが見て取れます。このように学習したモデルが実際の観測値を再現できるかを確認することはモデルの有効性を評価・確認する上で重要です。\n"});index.add({'id':6,'href':'/docs/vi_basic/','title':"変分推論の基礎",'section':"Docs",'content':" MathJax.Hub.Config({ tex2jax: { inlineMath: [['$', '$'] ], displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ] } });  変分推論の基礎 #  前節でベイズ学習の枠組みの３つの要点を簡単に説明しました。つまり\n  ベイズ学習とは観測データ$\\mathbf{X}$が得られたという条件下での未知のパラメータ$\\mathbf{w}$の確率分布、すなわち$p(\\mathbf{w}|\\mathbf{X})$を学習する作業であること。\n  一般的にベイズ学習は①対象とする事象の発生過程のモデル化（確率モデルの構築）を行ったうえで、②確率モデルと観測データをもとに未知パラメータを推論する、という枠組みで行うこと。\n  条件付き確率の定義から、$W$が離散変数の場合、$$p(\\mathbf{w}|\\mathbf{X})=\\frac{p(\\mathbf{w},\\mathbf{X})}{p(\\mathbf{X})}=\\frac{p(\\mathbf{w},\\mathbf{X})}{\\sum_{\\mathbf{w}} p(\\mathbf{w},\\mathbf{X})}\\tag{1}$$もしくは$W$が連続変数の場合、$$p(\\mathbf{w}|\\mathbf{X})=\\frac{p(\\mathbf{w},\\mathbf{X})}{p(\\mathbf{X})}=\\frac{p(\\mathbf{w},\\mathbf{X})}{\\int_{\\mathbf{w}} p(\\mathbf{w},\\mathbf{X})d\\mathbf{w}}\\tag{2}$$を計算することで$p(\\mathbf{w}|\\mathbf{X})$を推論することができること。\n  の３点です。\nしかし、前節で例示したような簡単な例を除いて、現実のほとんどの問題では、(1)式や(2)式の周辺分布（つまり和や積分の部分）は計算量が膨大であったり積分が解析的に不可能であり、厳密に計算できません。そこでこの周辺分布の計算を近似的にかつ現実的な時間内で計算する手法としてサンプリングや変分近似の手法が考案されてきました。ここではその１つである変分近似の手法について解説します。\n※ 以降では確率変数が連続変数の場合に限って説明をしていきますが離散変数の場合でも同様の議論が可能です。\n変分近似 #  我々は$p(\\mathbf{w}|\\mathbf{X})$を求めたいわけですが、この未知の確率分布がなんらかシンプルな関数$q(\\mathbf{w})$で表現できないかと考えます。この$q(\\mathbf{w})$を本来求めたい確率分布$p(\\mathbf{w}|\\mathbf{X})$に近づけていくことで$p(\\mathbf{w}|\\mathbf{X})$を近似的に求めてやろうという方法が変分近似です。\nここで$p(\\mathbf{w}|\\mathbf{X})$と近似関数$q(\\mathbf{w})$の類似度合いの指標としてKLダイバージェンスを採用すると変分近似は、 $$ q_{opt.}(\\mathbf{w})=\\underset{q}{\\operatorname{argmax}} \\operatorname{KL}(q(\\mathbf{w})||p(\\mathbf{w}|\\mathbf{X}))$$ の最適化問題として定式化できます。\nしかしKLダイバージェンスに未知の関数である$p(\\mathbf{w}|\\mathbf{X})$が入っているため、このままでは$q_{opt.}$を求めることはできません。そこでこのKLダイバージェンスの最小化問題を、数学的なトリックを使って別の計算可能な量の最大化問題に書き換えることで間接的にKLダイバージェンスを最小化する関数を求めることを行います。ではどのようにするのでしょうか？\nELBO #  ここで対数周辺尤度$\\ln{p(\\mathbf{X})}$を以下のように書き換えることができることに着目します。 $$ \\begin{align} \\ln{p(\\mathbf{X})} \u0026amp; = \\ln{p(\\mathbf{X})} \\int_{\\mathbf{w}} q(\\mathbf{w}) d\\mathbf{w}\\newline \u0026amp; = \\int_{\\mathbf{w}} q(\\mathbf{w}) \\ln\\frac{p(\\mathbf{X}, \\mathbf{w})}{p(\\mathbf{w} \\vert \\mathbf{X})} d\\mathbf{w}\\newline \u0026amp; = \\int_{\\mathbf{w}} q(\\mathbf{w}) \\ln \\frac{p(\\mathbf{X}, \\mathbf{w})~q(\\mathbf{w})}{p(\\mathbf{w} \\vert \\mathbf{X}) ~q(\\mathbf{w})} d\\mathbf{w}\\newline \u0026amp; = \\int_{\\mathbf{w}} q(\\mathbf{w}) \\ln \\frac{p(\\mathbf{X}, \\mathbf{w})}{q(\\mathbf{w})} d\\mathbf{w} + \\int_{\\mathbf{w}} q(\\mathbf{w}) \\ln \\frac{q(\\mathbf{w})}{p(\\mathbf{w} \\vert \\mathbf{X})} d\\mathbf{w}\\newline \u0026amp; = \\mathcal{L}(\\mathbf{X}) + \\operatorname{KL}(q\\vert \\vert p) \\end{align} $$ ここで１行目は $$ \\int_{\\mathbf{w}} q(\\mathbf{w}) d\\mathbf{w} = 1 $$ を使っています。\nここで$\\mathcal{L}(\\mathbf{X})$は、我々が仮定する関数$q(\\mathbf{w})$と確率モデル$p(\\mathbf{X}, \\mathbf{w})$から構成されているため計算が可能であることに注意してください。周辺尤度$p(\\mathbf{X})$は確率モデルと観測データが与えられれば一意的に値が決まる量なので、上の式はこの$\\mathcal{L}(\\mathbf{X})$を最大化する$q(\\mathbf{w})$を求めれば、それが自動的にKLダイバージェンスを最小化する$q(\\mathbf{w})$を求めていることになることを示しています。つまり未知の関数を含むKLダイバージェンスを直接最小化できなくても、代わりに$\\mathcal{L}(\\mathbf{X})$を最大化すればその目的が達成できるのです！\nこの$\\mathcal{L}(\\mathbf{X})$をELBO(Evidence Lower BOund)と呼びます。\nここで$q(\\mathbf{w})$をなんらかパラメータ$\\boldsymbol{\\alpha}$で特徴づけられる関数を仮定しているとすると、ELBO$\\mathcal{L}(\\mathbf{X})$の最大化、言い換えて$-\\mathcal{L}(\\mathbf{X})$の最小化はパラメータに対する偏微分$\\frac{\\partial \\mathcal{L}}{\\partial \\boldsymbol{\\alpha}}$を求めて勾配降下法で最適化計算を行っていくことができことになります。\n以上、変分近似について解説してきました。要点は、\n 事後確率$p(\\mathbf{w}|\\mathbf{X})$をパラメータ$\\boldsymbol{\\alpha}$で特徴づけられる関数（変分関数）$q(\\mathbf{w})$で表現する。 求めたい事後確率分布に変分関数を似せる（つまりKLダイバージェンスを最小化する）ことで事後分布を近似的に求める。 ただしKLダイバージェンスを直接計算できないので、代わりにELBOを最大化することで最適な変分関数$q_{opt.}(\\mathbf{w})$を求める。 ELBOの最大化は勾配降下法を用いて行う。 ということになります。  次節以降でPyroで変分近似を行う例を具体的に示していきます。\n"});})();