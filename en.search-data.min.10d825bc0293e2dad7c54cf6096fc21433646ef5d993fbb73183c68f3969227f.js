'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href','section'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/docs/bayes_learning_basic/','title':"Bayes Learning Basic",'section':"Docs",'content':" MathJax.Hub.Config({ tex2jax: { inlineMath: [['$', '$'] ], displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ] } });  ベイズ学習の枠組み #  ■ ベイズ学習は確率分布を学習する #  　ベイズ学習は、「事象（データ）$\\mathcal{D}$が観測された」という条件のもとでの未知の変数$\\mathbf{w}$の確率分布、すなわち事後確率分布$p(\\mathbf{w}|\\mathcal{D})$を推論する作業になります。一般的にベイズ学習は以下の２つのStepで行っていくといえます。\n 確率モデル（生成モデル）の構築：対象とする事象がどのような確率過程を経て生成されたのかをモデル化する。 推論：確率モデルと観測されたデータをもとに事後確率を求める。  それぞれのステップについて少し詳しく見ていきましょう。\n▼ Step1：確率モデル（生成モデル）の構築 #  　まず、着目する事象が確率的なプロセス\u0008から発生するものだという仮定を置き、そのプロセスをモデル化することから始めます。確率的な事象を確率変数によって定義し、確率変数の組み合わせで事象を表現していきます。このようなモデルを生成モデルと呼びます。また事象の確率プロセスがモデル化できるとそれはすなわち確率変数間の同時確率分布を定式化することになります。\n例：赤玉白玉問題 #  　赤玉と白玉が入っている袋があり、そこに入っている赤玉と白玉の数の割合$\\Theta$は未知とします。そこでこの袋から無作為に玉を取り出した結果$\\mathcal{D}$をもとに$\\Theta$を推測したいという課題を考えます。\n　この時ベイズ学習では$\\Theta$自体を確率変数と考え、観測データ$\\mathcal{D}$が得られた時の事後確率分布$p(\\Theta | \\mathcal{D})$を推論することになりますが、袋から取り出した時の色が決まる過程はどのようにモデル化できるでしょうか？\n　この問題の場合、下図のように①玉の割合は確率分布$p(\\Theta)$に従って確率的に決まり②$\\Theta$の実現値$\\theta$に準じて取り出す玉の色が確率的に決まるというようにモデル化することになります。\n  また同時確率は同時確率と条件付き確率の定義から $$ p(\\mathcal{D}, \\Theta)=p(\\mathcal{D}| \\Theta)p(\\Theta) $$ と書けることがわかります。\n▼ Step2：推論 #  Step1で確率モデルが構築できたら、そのモデルと観測データから未知のパラメータの確率分布を推論します。これはすなわち冒頭での話のとおり、観測データ$\\mathcal{D}$を得た条件下で未知のパラメータがとる条件付き確率$P(\\mathbf{w}|\\mathcal{D})$を推論することに相当します。 ではこの$P(\\mathbf{w}|\\mathcal{D})$はどう計算すれば良いのかを考えていきましょう。条件付き確率の定義から $$P(\\mathbf{w}|\\mathcal{D})=\\frac{P(\\mathbf{w},\\mathcal{D})}{P(\\mathcal{D})}=\\frac{P(\\mathbf{w},\\mathcal{D})}{\\sum_{\\mathbf{w}} P(\\mathbf{w},\\mathcal{D})}$$ と書き換えられます。 分子の同時確率はStep1の確率モデルの構築ができた時点で定式化されており求めることができるし、分母は未知のパラメータの取りえる値全てに関して同時確率を足し合わす（周辺化する）ことで求められます。\nつまりこの式は、どのような確率モデルの例であっても、同時確率とその未知のパラメータに対する周辺分布を計算することで事後分布$P(W|D)$を推論可能であるということを示していることになります。\n実際の複雑な確率モデルを扱う場合、周辺確率を求めるのに非常にコストがかかるためサンプリングや変分法と呼ばれる近似手法によって事後分布を計算するケースが多いですが、おおもとのベイズ学習の発想は「同時確率とその未知のパラメータに対する周辺分布から事後分布を計算する」ということにあることは覚えておいた方が良いでしょう。\n■ 推論の具体例 #  ここでは手で計算できるレベルの非常に単純なモデルを例に、実際に同時確率とその周辺確率から実際にベイズ推論を行ってみたいと思います。\n例：箱の中のボールの数の推論\nある箱の中にボールが３つ入っている。ボールの色は赤か白のどちらかだが、どの色が何個入っているかはわからない。ここで箱の中からランダムに１つボールを取り出しそのボールの色を確認後箱の中に戻すという操作を行う。 【ケースA】１回の試行で「白」が出た場合 【ケースB】３回の試行で「白→赤→白」が出た場合 の２つの場合で箱の中の白ボールの数がどのように推論できるかを見ていこう。\n【ケースA】１回の試行で「白」が出た場合 #  上のように、確率モデルの構築→推論とステップを踏んで進めていこう。\n確率モデルの構築 #  この場合の事象は下図のようなグラフィカルモデルで表せる。ここで$W={0, 1, 2, 3}$は白玉の数を示す確率変数で、$W$の値により試行時に取り出される玉の色$X={r, w}$の確率が決まるというモデルになっている。\n  また、簡単な確率の考察からそれぞれの確率は下表のようになる。ここで箱の中の玉の数は何の情報もないため等確率で発生するものとして$P_0(W)=1/4$、ここで$W={0,1, 2, 3}$としている。この$P_0(W)$を事前確率という。\n  推論 #  「１回の試行で白ボールを取り出した」というデータが確定したもとでの白ボールの数を推論したいので、求めたいのは事後確率$P(W|X_1=w)$であり、条件付き確率の定義から $$P(W|X_1=w)=\\frac{P(W,X_1=w)}{P(X_1=w)}=\\frac{P(W,X_1=w)}{\\sum_W{P(W, X_1=w)}}\\tag{1}$$ と書ける。上記の最左辺の分子と分母はこれまでの情報で計算できることがわかると思う。それぞれ求めていってみよう。 分子の同時確率は$P(W, X_1)=P(X_1|W)P(W)$であり、$P(W)_0=P(W)$とすると、 上の表から以下のように計算できる。 $$\\begin{cases}P(W=0, X_1=w) \u0026amp;= P(X_1=w|W=0)P_0(W=0)= 0 \\cdot \\frac{1}{4} = 0 \\\\ P(W=1, X_1=w) \u0026amp;= P(X_1=w|W=1)P_0(W=1)= \\frac{1}{3} \\cdot \\frac{1}{4} = \\frac{1}{12} \\\\ P(W=2, X_1=w) \u0026amp;= P(X_1=w|W=2)P_0(W=2)= \\frac{2}{3} \\cdot \\frac{1}{4} = \\frac{1}{6} \\\\ P(W=3, X_1=w) \u0026amp;= P(X_1=w|W=3)P_0(W=3)= 1 \\cdot \\frac{1}{4} = \\frac{1}{4} \\end{cases}$$\nまた(1)式の分母である周辺確率は $$P(X_1=w)=\\sum_{W}P(W, X_1=w) = 0+ \\frac{1}{12} + \\frac{1}{6} + \\frac{1}{4} = \\frac{1}{2}$$ となり、同様に$P(X_1=w)=\\frac{1}{2}$となる。\n(1)式にこれらの結果を代入すると $$\\begin{cases}P(W=0|X_1=w) \u0026amp;= 0 / \\frac{1}{2} = 0\\\\ P(W=1|X_1=w) \u0026amp;= \\frac{1}{12} / \\frac{1}{2} =\\frac{1}{6}\\\\ P(W=2|X_1=w) \u0026amp;= \\frac{1}{6} / \\frac{1}{2} =\\frac{1}{3}\\\\ P(W=3|X_1=w) \u0026amp;= \\frac{1}{4} / \\frac{1}{2} =\\frac{1}{2}\\\\ \\end{cases}$$ となり、１回目に白ボールが出た場合、確率的には箱の中のボールは全部白の可能性が一番高いと推論できることを示している。\n【ケースB】３回の試行で「白→赤→白」が出た場合 #  ケースAと同様の考察を繰り返すと良いです。 要点は、ボールを試行の度に箱に戻すため、Wが決定された状態では、各試行間は独立なので $$P(X_1,X_2,X_3)=P(X_1)P(X_2)P(X_3)$$ となることを利用することにあります。ここで実際の計算は練習問題としておきます。\n"});index.add({'id':1,'href':'/docs/pyro_modeling/','title':"Pyro Modeling",'section':"Docs",'content':" MathJax.Hub.Config({ tex2jax: { inlineMath: [['$', '$'] ], displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ] } });  Pyroによる確率モデリング #  前節で「Pyroにより確率変数やそれらを組み合わせた確率モデルを容易に扱うことが可能になる」ことを述べました。ここでは以下のような簡単な例をとおして、Pyroで確率変数をどのように扱うのか、確率モデルをどのように定義するのかなどを見ていきたいと思います。\n確率プリミティブ #  確率モデルは確率的にアウトプットが変動する「確率変数」から構成されます。\n例えばベルヌーイ分布に従う確率変数$x$を考える時、Pyroでは$x$を\nimport pyro x = pyro.sample(\u0026#34;x\u0026#34;, dist.Bernoulli(0.5)) のように宣言します。ここでpyro.sampleの第一引数は確率変数の名前を指定しており、のちに行う推論などではこの名前を確率変数のIDとして処理を行います（そのために一意に命名する必要があります。）。また第二引数は確率変数$x$の従う確率分布であり、ここでの例では1と0が等確率に出現するp=0.5のベルヌーイ分布を指定しています。\npyro.sample関数は指定された確率分布にしたがって値をサンプリングする関数となっており、以下の例で確率分布からサンプリングされている様子が確認することができます。\nfor _ in range(5): x = pyro.sample(\u0026#34;x\u0026#34;, dist.Bernoulli(0.5)) print(x) ## output # tensor(1.) # tensor(1.) # tensor(0.) # tensor(1.) # tensor(0.) 簡単なモデルの例 #  確率プリミティブを用いて簡単な確率モデルをPyroで定義する例をみてみましょう。ここでは以下のような例を考えます。\n例:赤玉白玉問題 下図のように、２つの袋$a$および$b$があり、袋$a$には赤玉が2個、白玉が1個入っており、袋$b$には赤玉が1個、白玉が3個入っているものとします。ここで、２つの袋のうち一方の袋を等確率にランダムに選び、その選んだ袋から玉を１つ取り出す試行を行います。\n  ここで「袋が選ばれる」「玉が取り出される」という確率的な過程をそれぞれ確率変数$x$、$y$とすると上の試行は下記のグラフィカルモデルのように記述出来ます。   Pyroでは確率モデルを確率プリミティブの演算の組み合わせで構成されたPython関数として定義します。上の確率モデルであれば下記のball_modelのように定義することができます。このように観測値（今回の場合は取り出した玉の色）がどのような確率過程で生み出されたのかを記述するようなモデルを生成モデルと呼びます。\nimport pyro import pyro.distributions as dist # x=1: 袋a, x=0: 袋b # y=1: 赤玉, y=0:　白玉 def ball_model(): x = pyro.sample(\u0026#34;x\u0026#34;, dist.Bernoulli(0.5)) if x: y = pyro.sample(\u0026#34;y\u0026#34;, dist.Bernoulli(2.0/3.0)) else: y = pyro.sample(\u0026#34;y\u0026#34;, dist.Bernoulli(1.0/4.0)) return y 7行目でxとしてどちらかの袋を等確率に選ぶためp=0.5のベルヌーイ分布を指定しています。変数xは1(袋a）か0（袋b）を出力しますが、その出力値に応じてそれぞれの袋の中の赤玉と白玉の数に合わせてベルヌーイ分布で赤玉白玉が選択されるように実装されているのがわかります。\n確率プリミティブの組み合わせで構成されたball_modelの関数もやはり確率的な挙動を示す確率的関数として動作し、下記のコード例のように、関数が呼ばれたらその関数内で定義されたモデルに従って値をサンプリングする動作をします。\nfor _ in range(5): print(ball_model()) ## output # tensor(0.) # tensor(0.) # tensor(1.) # tensor(0.) # tensor(1.) モデル内部状態の把握 #  ここまでで、確率モデルをPythonの関数として実装し、それを呼ぶことで確率モデルに従った最終的な実現値をサンプリングすることができました。推論などを行う際には実現値を出力するに至るまでにそのモデルの内部の確率変数がどういう値を取ったのかを知りたい場合が多くあります。Pyroではtraceを用いることでそのサンプリング過程をトレースすることが可能になります。\n下のコードはball_modelをサンプリングしその時の内部状態を出力しています。 この出力内容を見ると、ball_modelには関数内で明示的に定義した'x', 'y'の他に'_INPUT'、'_RETURN'というノードも存在することがわかります。また今回のモデルの実現値は内部のそれぞれの確率変数の実現値（value）が'x'=tensor(0.)、'y'=tensor(1.)となることでモデルの最終的な出力'_RETURN'の実現値がtensor(1.)となっていることが窺い知ることができます。\nfrom pyro.poutine import trace tr = trace(ball_model).get_trace() for tr_items in tr.nodes.items(): print(tr_items) # output # (\u0026#39;_INPUT\u0026#39;, {\u0026#39;name\u0026#39;: \u0026#39;_INPUT\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;args\u0026#39;, \u0026#39;args\u0026#39;: (), \u0026#39;kwargs\u0026#39;: {}}) #(\u0026#39;x\u0026#39;, {\u0026#39;type\u0026#39;: \u0026#39;sample\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;x\u0026#39;, \u0026#39;fn\u0026#39;: Bernoulli(probs: 0.5), \u0026#39;is_observed\u0026#39;: False, \u0026#39;args\u0026#39;: (), \u0026#39;kwargs\u0026#39;: {}, \u0026#39;value\u0026#39;: tensor(0.), \u0026#39;infer\u0026#39;: {}, \u0026#39;scale\u0026#39;: 1.0, \u0026#39;mask\u0026#39;: None, \u0026#39;cond_indep_stack\u0026#39;: (), \u0026#39;done\u0026#39;: True, \u0026#39;stop\u0026#39;: False, \u0026#39;continuation\u0026#39;: None}) # (\u0026#39;y\u0026#39;, {\u0026#39;type\u0026#39;: \u0026#39;sample\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;y\u0026#39;, \u0026#39;fn\u0026#39;: Bernoulli(probs: 0.25), \u0026#39;is_observed\u0026#39;: False, \u0026#39;args\u0026#39;: (), \u0026#39;kwargs\u0026#39;: {}, \u0026#39;value\u0026#39;: tensor(1.), \u0026#39;infer\u0026#39;: {}, \u0026#39;scale\u0026#39;: 1.0, \u0026#39;mask\u0026#39;: None, \u0026#39;cond_indep_stack\u0026#39;: (), \u0026#39;done\u0026#39;: True, \u0026#39;stop\u0026#39;: False, \u0026#39;continuation\u0026#39;: None}) # (\u0026#39;_RETURN\u0026#39;, {\u0026#39;name\u0026#39;: \u0026#39;_RETURN\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;return\u0026#39;, \u0026#39;value\u0026#39;: tensor(1.)}) また下記のコードのようにconditionを用いて各確率変数の実現値を固定してトレースすることで確率モデルの同時確率を求めることも可能です。\nfrom pyro import condition cond_model = condition(ball_model, { \u0026#34;x\u0026#34;: tensor(1.), \u0026#34;y\u0026#34;: tensor(1.) }) tr = trace(cond_model).get_trace() for tr_items in tr.nodes.items(): print(tr_items) print(\u0026#39;p(x=1, y=1) =\u0026#39;, tr.log_prob_sum().exp().item()) ### output # (\u0026#39;_INPUT\u0026#39;, {\u0026#39;name\u0026#39;: \u0026#39;_INPUT\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;args\u0026#39;, \u0026#39;args\u0026#39;: (), \u0026#39;kwargs\u0026#39;: {}}) # (\u0026#39;x\u0026#39;, {\u0026#39;type\u0026#39;: \u0026#39;sample\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;x\u0026#39;, \u0026#39;fn\u0026#39;: Bernoulli(probs: 0.5), \u0026#39;is_observed\u0026#39;: True, \u0026#39;args\u0026#39;: (), \u0026#39;kwargs\u0026#39;: {}, \u0026#39;value\u0026#39;: tensor(1.), \u0026#39;infer\u0026#39;: {}, \u0026#39;scale\u0026#39;: 1.0, \u0026#39;mask\u0026#39;: None, \u0026#39;cond_indep_stack\u0026#39;: (), \u0026#39;done\u0026#39;: True, \u0026#39;stop\u0026#39;: False, \u0026#39;continuation\u0026#39;: None}) # (\u0026#39;y\u0026#39;, {\u0026#39;type\u0026#39;: \u0026#39;sample\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;y\u0026#39;, \u0026#39;fn\u0026#39;: Bernoulli(probs: 0.6666666865348816), \u0026#39;is_observed\u0026#39;: True, \u0026#39;args\u0026#39;: (), \u0026#39;kwargs\u0026#39;: {}, \u0026#39;value\u0026#39;: tensor(1.), \u0026#39;infer\u0026#39;: {}, \u0026#39;scale\u0026#39;: 1.0, \u0026#39;mask\u0026#39;: None, \u0026#39;cond_indep_stack\u0026#39;: (), \u0026#39;done\u0026#39;: True, \u0026#39;stop\u0026#39;: False, \u0026#39;continuation\u0026#39;: None}) # (\u0026#39;_RETURN\u0026#39;, {\u0026#39;name\u0026#39;: \u0026#39;_RETURN\u0026#39;, \u0026#39;type\u0026#39;: \u0026#39;return\u0026#39;, \u0026#39;value\u0026#39;: tensor(1.)}) # p(x=1, y=1) = 0.3333333134651184 複雑な確率モデル #  確率モデルをPythonの関数の形でかけるということは様々なメリットがあります。下記のコード例のように確率モデルに引数を渡したり、再帰的な確率モデルを構築することも容易ですし、関数同士を組み合わせることも可能です。\ndef geometric(p, t=None): if t is None: t = 0 x = pyro.sample(\u0026#34;x_{}\u0026#34;.format(t), pyro.distributions.Bernoulli(p)) if x.item() == 1: return 0 else: return 1 + geometric(p, t + 1) print(geometric(0.5)) ## output # 0 ベイズ学習へ #  ここまででPyroを用いて対象の事象に合わせた確率モデル、いわゆる生成モデルを定義することを行ってきました。ベイズ学習ではこの確率モデルに観測されたデータを組み合わせることで、未知のパラメータを学習・推論することになります。例えば、前述の赤玉白玉問題の場合、取り出された玉の色のデータをもとに袋の中の赤玉の数を推定していくことを行います。\nPyroを用いてベイズ学習を実装していく前に、必要最小限のベイズ学習の知識を復讐していきましょう。\n"});index.add({'id':2,'href':'/docs/mle_map/','title':"MAP推定と最尤推定",'section':"Docs",'content':" MathJax.Hub.Config({ tex2jax: { inlineMath: [['$', '$'] ], displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ] } });  MAP推定と最尤推定 #  前節までで変分近似を用いてベイズ推論を行ってきました。ベイズ推論は観測出来ない潜在パラメータを確率変数と捉え、ベイズの定理を利用して観測データ$\\mathbf{X}$からそのパラメータの確率分布を推定するものでした。つまり潜在パラメータの確率変数を$\\Theta$とすると下記の関係性を用いて事後分布$p(\\Theta|\\mathbf{X})$を求めることがベイズ推定です。 $$ p(\\Theta|\\mathbf{X}) = \\frac{p(\\mathbf{X}|\\Theta)p(\\Theta)}{p(\\mathbf{X})}\\tag{1} $$\n一方でわざわざ確率分布まで求めなくても、確率分布の最も頻度が高くなる一点を簡易的に求めれば事足りる場合も多々あります。そのような手法としてMAP推定や最尤推定と呼ばれる手法があります。本節ではこれらを紹介したうえでPyroでの計算方法を紹介します。\n※ 以下のコードの全体は Githubリポジトリに置いています。\n■MAP推定 #  MAP推定のMAPはmaximum a posterioriの略であり、日本語に訳すと最大事後確率推定と呼ばれます。その名のとおり観測データに対して事後分布$p(\\Theta|\\mathbf{X})$が最大となるパラメータ値を推定する、つまり、 $$ \\theta_{MAP} = \\underset{\\theta}{\\operatorname{argmax}}~p(\\Theta=\\theta|\\mathbf{X})=\\underset{\\theta}{\\operatorname{argmax}}~p(\\mathbf{X}|\\Theta=\\theta)p(\\theta)\\tag{2} $$ となる$\\theta_{MAP}$を求める作業になります。ここで２つ目の等式は(1)式の関係性から容易に導けるでしょう。\nさて、これまで変分推論では事後確率に近しいと想定される近似関数$q(\\theta)$を用意し、その近似関数の形が本来求めたい事後確率分布に近づくように近似関数のパラメータを最適化しました。その変分推論の枠組みに当てはめたとき、(2)式は近似関数$q(\\theta)$をデルタ関数$\\delta(\\theta-\\theta_{MAP})$と仮定して変分推論することとして解釈が可能です。\nここでデルタ関数$\\delta(\\theta-\\theta_{MAP})$は$\\theta=\\theta_{MAP}$で∞になり、それ以外の$\\theta$ではゼロをとる無限に尖った関数であり$\\int\\delta(\\theta-\\theta_{MAP})d\\theta=1$となります。\n以上のとおりMAP推定をデルタ関数を近似関数とした変分推論と解釈できるならPyroでもguide関数にデルタ関数を指定してあげれることでMAP推定を行うことができます。実際に前節の赤玉白玉の混合比率を例にPyroでMAP推定してみましょう。\n試行データ生成 #  試行結果データを生成するコードは前節と全く同様です。\n# 試行データ作成（前節と同一コード） def create_data(red_num, white_num): red = torch.tensor(1.0) white = torch.tensor(0.0) data = [] for _ in range(red_num): data.append(red) for _ in range(white_num): data.append(white) random.shuffle(data) data = torch.tensor(data) return data data = create_data(6, 4) 最適化ヘルパー関数を定義 #  後ほど最尤推定でも再利用できるように最適化の一連の処理を関数化します。\n# 最適化計算用のヘルパー関数 #　引数として指定されたmodelの関数とguide関数を用いてELBOの最大化を行う def optimize_param(model_fn, guide_fn): # グローバル変数として保存されているパラメータを削除 pyro.clear_param_store() # Optimizerの定義と設定（Adamの利用が推奨されている） adam_params = {\u0026#34;lr\u0026#34;: 0.001, \u0026#34;betas\u0026#34;: (0.95, 0.999)} optimizer = Adam(adam_params) # 推論アルゴリズムとLoss値を定義 # ここでは組み込みのELBOの符号反転をLoss値とする`Trace_ELBO()`を利用しています。 svi = SVI(model_fn, guide_fn, optimizer, loss=Trace_ELBO()) # 最適化の逐次計算 # ここではAdamで勾配降下を1000回繰り返すことになる。 n_steps = 1000 losses = [] for step in range(n_steps): loss = svi.step(data) losses.append(loss) if step % 100 == 0: print(\u0026#39;#\u0026#39;, end=\u0026#39;\u0026#39;) plt.plot(losses) plt.show() 確率モデルと変分関数 #  上述のようにMAP推定は変分推論の枠組みで変分関数としてデルタ関数を仮定するものというお話をしました。そのため確率モデルは前節と全く同じでよく、また変分関数を規定するguide関数はデルタ分布を用います。\n# 確率モデルの定義 def model(data): # 事前確率分布は比率0.5に穏やかなピークを持つ関数を仮定する。 alpha0 = torch.tensor(2.0) beta0 = torch.tensor(2.0) f = pyro.sample(\u0026#34;Theta\u0026#34;, dist.Beta(alpha0, beta0)) # 観測データのプレート定義 with pyro.plate(\u0026#39;observation\u0026#39;): pyro.sample(\u0026#39;X\u0026#39;, dist.Bernoulli(f), obs=data) # MAP推定や最終推定は変分関数としてデルタ関数を仮定する。 def guide_delta(data): theta_opt = pyro.param(\u0026#34;theta_opt\u0026#34;, torch.tensor(0.5), constraint=constraints.unit_interval) pyro.sample(\u0026#34;Theta\u0026#34;, dist.Delta(theta_opt)) 確率モデルと変分関数が用意できたら、変分関数のパラメータ（今回の場合theta_opt）の最適化を行います。\n#　MAP推定用のmodel関数とguide関数を指定して最適化を実施 optimize_param(model_map, guide_delta) # 最適化後の変分パラメータを取得する theta = pyro.param(\u0026#34;theta_opt\u0026#34;).item() print(\u0026#34;theta_opt = {:.3f}\u0026#34;.format(theta)) ## Output # theta_opt = 0.583 上記の結果、thata_optつまり$\\theta_{MAP}$は0.583となりました。前節で行ったベイズ推定結果の事後確率分布の最頻値とほぼ同じ値が求まったことに注意してください。これはMAP推定が全体の確率分布までは求めないけど確率分布の最頻値をとる潜在パラメータの値を求める推定方法であることを考えると納得がいくでしょう。\nまた、試行データを作成する際に、data = create_data(60, 40)として、合計100回の試行データを作成するとtheta_opt = 0.599となります。これは試行回数が増えれば増えるほど、最初に想定していた事前確率分布よりも試行データのほうが重みが増えて試行データの結果の比に近づいていくことを示しています。\n■最尤推定 #  単に観測データ$\\mathbf{X}$に対する尤度が最大となる$\\theta$を求める、すなわち $$ \\theta_{MLE} = \\underset{\\theta}{\\operatorname{argmax}}~p(\\mathbf{X}|\\Theta=\\theta) $$ となる$\\theta_{MLE}$を求めるのが最尤推定（Maximum Likelihood Estimation: MLE）です。\nこれは(2)式と見比べると潜在パラメータの事前分布を$p(\\Theta)$を一定値とした（すなわち事前情報がないとした）MAP推定をしていると解釈することができます。\n以上のことからPyroで最尤推定を行うには場合、事前分布を一様分布としてMAP推定を行えばよいことが分かります。確率モデルは下記のように定義することができます。0~1の範囲で一様分布となるdist.Uniform(0.0, 1.0)で事前分布が定義されているのに注意してください。\n# 最尤推定用に確率モデルの定義（ベイズ推定の際と全く同じことに注意） def model_mle(data): # 事前確率分布は一定値（無情報）として一様分布を指定する f = pyro.sample(\u0026#34;Theta\u0026#34;, dist.Uniform(0.0, 1.0)) # 観測データのプレート定義 with pyro.plate(\u0026#39;observation\u0026#39;): pyro.sample(\u0026#39;X\u0026#39;, dist.Bernoulli(f), obs=data) 上記の確率モデル関数を用いて最適化を以下のように行うことができます。\n#　MAP推定用のmodel関数とguide関数を指定して最適化を実施 optimize_param(model_mle, guide_delta) # 最適化後の変分パラメータを取得する theta = pyro.param(\u0026#34;theta_opt\u0026#34;).item() print(\u0026#34;theta_opt = {:.3f}\u0026#34;.format(theta)) ## Output theta_opt = 0.600 thata_optつまり$\\theta_{MAP}S$は0.600となりました。\nちなみにdata = create_data(3, 2)というように試行回数を幾ら減らしたデータを用いてもtheta_opt=0.600という結果は変わりません。これは最尤推定では例えば比率が半分である可能性が高いといったような事前情報を導入していないため、試行データだけをもとに混合比率を推定したことに起因します。その結果「赤玉と白玉がそれぞれ3回と2回取り出された」という結果に過剰適合（Overfitting）した結果になります。\n"});index.add({'id':3,'href':'/docs/pyro_vi/','title':"Pyroで変分推論",'section':"Docs",'content':" MathJax.Hub.Config({ tex2jax: { inlineMath: [['$', '$'] ], displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ] } });  変分推論を試す #  前節で変分近似は、\n 対象の事象の発生過程を確率モデルとしてモデリングする。 推定したいパラメータが従う事後確率分布の近似関数（変分関数）を仮定する。 変分関数と真の事後関数のKLダイバージェンスを最小化する（＝ELBOを最大化する）。  という手順で行うことを説明しました。この節ではPyroを用いて変分推論を具体的に行っていく手順を見ていきます。Pyroでも上の手順をたどっていくことになります。以下の簡単な例を用いてその手順を１つずつ見ていくことにします。\n例：袋の中のボールの比率の推論\n赤玉と白玉が入っている中身が見えない袋があります。袋の中の赤玉と白玉の数は同数入っている（混合比率=0.5）という事前情報がありますが、実際のところはわかっていません。そこで袋の中からランダムに１つを取り出しそのボールの色を確認後、箱の中に戻すという操作を複数回行います。 この時、10回の試行で赤が６回、白が４回が出た場合、玉の混合比率についてどういう推論が可能でしょうか？ベイズ推論の枠組みに従い混合比率の確率分布をPyroを用いて推論していくことにします。\n※ 以下のコードの全体は Githubリポジトリに置いています。\n試行データ #  ここでまず上記例の試行結果のデータを作っておきます。\n# 試行データ作成 def create_data(red_num, white_num): red = torch.tensor(1.0) white = torch.tensor(0.0) data = [] for _ in range(red_num): data.append(red) for _ in range(white_num): data.append(white) random.shuffle(data) data = torch.tensor(data) return data data = create_data(6, 4) 確率モデルの構築 #  混合比率の推論に向けて、まず最初に今回の事象が発生する確率モデルを構築します。\n$i$回目の試行で取り出される玉の色を表す確率変数を$X_i \\in \\lbrace\\text{赤, 白}\\rbrace$とします。例えば混合率（今回は赤玉の比率）を$\\theta$とすると、$\\theta$に応じて$X_i$の実現値が決まると考えられるでしょう。ベイズ機械学習ではこの混合比率$\\theta$も確率的に決まる値であり確率変数$\\Theta$の実現値と考えます。つまり取り出される玉の色は以下の過程で決まるとモデル化します。1\n 混合率の実現値$\\theta$が、事前確率分布$p(\\Theta)$に従って決まる。 混合率が$\\theta$と決まった条件下で、$\\theta$に応じて確率$p(X_i|\\Theta=\\theta)$で玉の色が決まる。  この確率モデルをグラフィカルモデルで記述すると以下の図のようになります。今回の試行は混合率が$\\Theta=\\theta$と決まった条件下で各試行間は独立の関係（条件付き独立）となっています。そこで「プレート表現」を使って$N$回の試行を１つにまとめて表現しています。また玉の色は観測されるもので事後確率を考える上での「条件」となるので変数Xに相当するノードが塗り潰されています2。\n  またこの時、試行回数$N$とした時の同時確率分布は以下のように書けます。ここで$x_i$は$i$回目での思考の玉の色の実現値を示しています。 $$p(\\mathbf{X}=\\mathbf{x}, \\Theta=\\theta)=\\prod_{i=1}^{N} p(X_i=x_i|\\Theta=\\theta)~p(\\Theta=\\theta)$$\nさて、上記ステップ2.の取り出される色の確率分布は比率$\\theta$をパラメータとしたベルヌーイ分布と仮定するのが自然でしょう。つまり $$p(X_i|\\Theta=\\theta)=\\operatorname{Bern}(X_i, \\theta)$$\nと仮定します。 また今回の例の場合、袋の中には赤玉と白玉同数入っているという事前情報があるのでそれをモデルに取り込むために、比率0.5に穏やかなピークをもつベータ分布 $$p(\\Theta)=\\operatorname{Beta}(\\Theta|\\alpha = 2, \\beta = 2)$$ と仮定します3。\nこの確率モデルをPyroで記述してみます。前節で述べたとおりPyroでは確率モデルを確率プリミティブを組み合わせた関数の形で記述します。今回のモデルは以下の様に実装することができます。\n# 確率モデルの定義 def model(data): # 事前確率分布は比率0.5に穏やかなピークを持つ関数を仮定する。 alpha0 = torch.tensor(2.0) beta0 = torch.tensor(2.0) f = pyro.sample(\u0026#34;Theta\u0026#34;, dist.Beta(alpha0, beta0)) # 観測データのプレート定義 with pyro.plate(\u0026#39;observation\u0026#39;): pyro.sample(\u0026#39;X\u0026#39;, dist.Bernoulli(f), obs=data) Pyroでは条件付き独立な関係の確率変数を,グラフィカルモデルと同様にplateとしてまとめる機能を持っており、8,9行目ではそれを利用してモデル化しているのに注意してください。\n変分関数を仮定 #  今回、我々は玉を取り出した結果をもとに玉の混合比率の確率分布$p(\\Theta|X)$を求めようとしています。変分近似ではこの未知の分布をなんらかパラメータを用いて簡単に記述できる分布（変分関数）を仮定してそのパラメータを推定するのでした。ここでは変分関数としてベルヌーイ分布の共役事前分布であるベータ分布を採用し、ベータ分布のパラメータ$\\alpha, \\beta$を推定する問題に帰着させます。\nPyroでは変分関数の定義もモデルの定義と同様に確率プリミティブを組み合わせた関数の形で記述します。Pyroではこの変分関数を定義する関数をguideと呼びます。\ndef guide(data): # 変分パラメータαとβを定義する。 # 初期値は共に10としている。 # また、ベータ分布においてこれらのパラメータは正の値なので`constraints.positive`を指定。 alpha_q = pyro.param(\u0026#34;alpha_q\u0026#34;, torch.tensor(10.0), constraint=constraints.positive) beta_q = pyro.param(\u0026#34;beta_q\u0026#34;, torch.tensor(10.0), constraint=constraints.positive) # 最適化されたパラメータのベータ分布から混合率Θをサンプリングする pyro.sample(\u0026#34;Theta\u0026#34;, dist.Beta(alpha_q, beta_q)) guideを定義する際、以下の点に注意する必要があります。\n guide関数の引数はmodel関数を定義した際の引数と同一であること。 学習対象である変分パラメータ（ここでは$\\alpha, \\beta$）をpyro.paramを用いて定義します。これは後にELBOの各パラメータの偏微分値を求めるために、requires_gradフラグをTrueにセットしたtorch.tensor型の変数として各変分パラメータを定義していることに相当します。  またここではベータ分布において$\\alpha, \\beta$は正の値のためconstraint=constraints.positiveとして最適化過程で取りえる値に制約を加えています。\n最適化 #  変分関数が定義できたので、その中で変分パラメータとして定義したalpha_qとalpha_qをELBOが最大化するように最適化計算を行います。具体的には以下のコードのように実装します。\n# グローバル変数として保存されているパラメータを削除 pyro.clear_param_store() # Optimizerの定義と設定（Adamの利用が推奨されている） adam_params = {\u0026#34;lr\u0026#34;: 0.002, \u0026#34;betas\u0026#34;: (0.95, 0.999)} optimizer = Adam(adam_params) # 推論アルゴリズムとLoss値を定義 # ここでは組み込みのELBOの符号反転をLoss値とする`Trace_ELBO()`を利用しています。 svi = SVI(model, guide, optimizer, loss=Trace_ELBO()) # 最適化の逐次計算 # ここではAdamで勾配降下を1000回繰り返すことになる。 n_steps = 1000 losses = [] for step in range(n_steps): loss = svi.step(data) losses.append(loss) if step % 100 == 0: print(\u0026#39;#\u0026#39;, end=\u0026#39;\u0026#39;) plt.plot(losses) ここで、最適化を行う前に、pyro.clear_param_store()を実行しています。これはPyroではグローバル変数として各変分パラメータを保持しているため、それを消す処理を行っています。 またこのコードでは、svi.step()はLoss値（ELBOの符号逆転値）が返却されるので、Lossの変化をプロットしています。結果は以下の図のようになります。SVI(Stochastic Variational Inference)は確率的勾配降下法(SGD)と同様に計算速度を上げるためにミニバッチで勾配計算を行う4ためLossがランダムに振動していますが、1000回イタレーションを繰り返すと、ELBOが小さいところで落ち着いているのが見てとれます。\n  この最適化後の変分パラメータは以下のコードのようにpyro.paramで取得できます。\n# 最適化後の変分パラメータを取得する alpha_q = pyro.param(\u0026#34;alpha_q\u0026#34;).item() beta_q = pyro.param(\u0026#34;beta_q\u0026#34;).item() print(\u0026#34;alpha_q = {:.2f}, beta_q = {:.2f}\u0026#34;.format(alpha_q, beta_q)) ## Output #alpha_q = 10.55, beta_q = 7.80 我々は混合分布の事後確率分布をベータ分布と仮定していましたから、上記のパラメータを用いて事後確率分布の様子をプロットして確認してみましょう。\n# 得られたパラメータを用いて事後確率分布をプロット x_range = np.arange(0.0, 1.0, 0.01) estimated_dist = dist.Beta(alpha_q, beta_q) y = [estimated_dist.log_prob(torch.tensor([x])).exp() for x in x_range] plt.plot(x_range, y) 得られるグラフは下図のようになります。事後分布$p(\\Theta|X)$は0.6付近が最も大きくなっており、これは10回の試行で赤が6回出た観測事象と辻褄が合っているのがわかります。ただし10回の観測ではまだ混合比率に曖昧性があり、確率分布の裾野が比較的広い確率分布となります。\n  より具体的に今回推論された確率分布の最頻値を求めてみましょう。 計算結果は以下のようになります。 ここで、最頻値0.584となっており、観測結果の0.6より小さくなっているのに注意してください。これは事前確率として0.5をピークに持つ関数を設定していることにより起きています。観測だけを信じると0.6ですが、試行回数が10回程度であればその結果だけを信じて取り込むよりも事前情報の0.5もある程度加味された事後分布になっているという状況です。\n# 最頻値を計算 mode = (alpha_q - 1) / (alpha_q + beta_q - 2) print(\u0026#34;mode = {:.3f}\u0026#34;.format(mode)) # 平均値を計算 mean = alpha_q / (alpha_q + beta_q) # 標準偏差を計算 factor = beta_q / (alpha_q * (1.0 + alpha_q + beta_q)) std = mean * np.sqrt(factor) print(\u0026#34;infered ratio = {:.3f} +- {:.3f}\u0026#34;.format(mean, std)) ## Output # mode = 0.584 # infered ratio = 0.575 +- 0.112 さらに観測回数を増やして1000回の試行でそのうち赤が600回、白が400回取り出された場合はどのような混合比率の事後分布になるでしょうか？ 試行データ作成時にdata = create_data(600, 400)としてデータを作成して同様の推論を行ってみます。 すると結果の事後分布は下記のような形となり、10回の時よりも混合比率が0.6である確信が強まり、確率分布の裾野が10回の思考の場合よりも狭まっているのがわかります。\n  以上、Pyroを用いて簡単な例での変分推定のやり方を見てきました。今回のコードは Githubに配置していますので参考にしてみてください。\n補足：pyro.plateを用いたサンプリングについて #  今回の例では確率モデルをPyro上で記述する際にコンテキストマネージャであるpyro.plateを用いて複数の観測を記述しました。\nこのpyro.plateは記述を簡潔にすることに加えて、このコンテキスト内でサンプルされた事象間はお互いに独立であることをPyroに明示的に伝える役割があります。このことは特に推論時の処理時間に非常に大きな影響を与えます。サンプル間が非独立である場合、Pyroはサンプリングをforループのように逐次的に行う必要がありますが、独立である場合は並列でサンプリングすることができるからです。\n下記に、同じ確率分布の確率変数の実現値を①逐次的にサンプルするコード、②pyro.plateを用いて並列サンプリングを行ったコードの２つを示します。同じ10万回のサンプルにもかかわらずpyro.plateを用いた場合のほうが圧倒的に処理速度が速いことがわかります。また並列サンプリングされた変数値は１つのTensorに格納されていることにも注意してください。\nそこで変数間が独立であることがわかっている場合は積極的にpyro.plateを用いることが推奨されます。\n# 正規分布をFor文を用いて逐次的にサンプリング start = time.time() samples = [] for i in range(100000): sampled_item = pyro.sample(\u0026#34;sample_{}\u0026#34;.format(i), dist.Normal(0, 1)) samples.append(sampled_item) print(\u0026#39;elapsed_time = {:.5f} sec\u0026#39;.format(time.time() - start)) print(\u0026#39;The shape of sampled variable = \u0026#39;, sampled_item.size()) print(\u0026#39;The sampled variable = \u0026#39;, sampled_item) ### Output # elapsed_time = 7.31403 sec # The shape of sampled variable = torch.Size([]) # The sampled variable = tensor(-0.5368) # pyro.plateを用いて１つの変数（Tensor）でサンプリング場合 start = time.time() with pyro.plate(\u0026#34;plate1\u0026#34;, size=100000): samples = pyro.sample(\u0026#34;samples\u0026#34;, dist.Normal(0, 1)) print(\u0026#39;elapsed_time = {:.5f} sec\u0026#39;.format(time.time() - start)) print(\u0026#39;The shape of sampled variable = \u0026#39;, samples.size()) plt.hist(samples, bins=50) ### Output # elapsed_time = 0.00705 sec # The shape of sampled variable = torch.Size([100000])   この様に観測事象の生成過程を仮定してモデリングする確率過程を生成モデルと呼びます。 \u0026#x21a9;\u0026#xfe0e;\n グラフィカルモデルの詳細は例えば このレビュー論文でわかりやすく解説されているので参照してください。 \u0026#x21a9;\u0026#xfe0e;\n ここで事前分布としてベータ関数を採用のは単に確率変数の定義域が0~1かつ一様分布の確率分布を採用したいという動機であり、後のステップで変分関数としてベータ関数を採用するのとは無関係であることに注意してください。 \u0026#x21a9;\u0026#xfe0e;\n  Variational Inference: A Review for Statisticians \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':4,'href':'/docs/what_is_pyro/','title':"Pyroとは",'section':"Docs",'content':"Pyroとは #   PyroはUber AI labにより開発されている、オープンソースの確率的プログラミング言語(Probablistic Programing Language: PPL)です1。Python上で動作し、Pythonのコードを実装する要領で、確率変数やそれらを組み合わせた独自の確率モデルを構築することを可能にしてくれます。\nまた同時に確率モデルの推論を行うための多くのアルゴリズムが実装されており、本書のメイントピックであるベイズ機械学習（以降、ベイズ学習）を非常にシンプルな形で実装することが可能になります。特に変分推論においては学習時に最大化していく対象であるELBO(Evidence Lower Bound)をユーザーが構築した独自の確率モデルに従って自動で計算する機能を備えており、Pyroを用いると変分推論の実装が非常に容易になります2。このような機能により深層学習とベイズ学習を組み合わせた深層ベイズ学習などの実装も非常に容易になります。\nPyroはそのバックエンドに深層学習フレームワークの Pytorchを利用しているため、Pytorchのもつ自動微分(autograd)機能やGPU計算機能を利用することで高速な学習が可能になっているところに特徴があります。\nPyroのインストール #  ローカル環境へのPyroのインストール #  自身のローカル環境でPyroを利用する場合、まずは、まず Pytorchをインストールする必要があります。Pytorchをインストール後、\npip install pyro-ppl コマンドによりPyroのインストールします。\nGoogle ColabratoryでのPyroのインストール #  以降の本書のサンプルコードは全て Google Colabratory上で動作させることを前提としています。ColabratoryはPytorchは事前にインストールされているため、下記の「!」を冒頭につけたpipコマンドをセル上で動かすだけででPyroをインストールすることが可能です。\n!pip install pyro-ppl 次節以降で、ベイズ学習の基礎とPyroを用いた実装方法を学んでいきます。\n  「プログラミング言語」と名乗ってはいますが、Pythonで動作するライブラリの位置付けなので、確率的プログラミングをするための「フレームワーク」と考えた方がわかりやすいかもしれません。 \u0026#x21a9;\u0026#xfe0e;\n これは言うなれば深層学習においてTensorflowやPytorchがユーザーが独自に構築したニューラルネットワークの損失関数の勾配を自動で計算してくれることに対応していると考えれば、この機能の便利さが容易に想像できます。 \u0026#x21a9;\u0026#xfe0e;\n   "});index.add({'id':5,'href':'/docs/vi_basic/','title':"変分推論の基礎",'section':"Docs",'content':" MathJax.Hub.Config({ tex2jax: { inlineMath: [['$', '$'] ], displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ] } });  変分推論の基礎 #  前節でベイズ学習の枠組みの３つの要点を簡単に説明しました。つまり\n  ベイズ学習とは観測データ$\\mathbf{X}$が得られたという条件下での未知のパラメータ$\\mathbf{w}$の確率分布、すなわち$p(\\mathbf{w}|\\mathbf{X})$を学習する作業であること。\n  一般的にベイズ学習は①対象とする事象の発生過程のモデル化（確率モデルの構築）を行ったうえで、②確率モデルと観測データをもとに未知パラメータを推論する、という枠組みで行うこと。\n  条件付き確率の定義から、$W$が離散変数の場合、$$p(\\mathbf{w}|\\mathbf{X})=\\frac{p(\\mathbf{w},\\mathbf{X})}{p(\\mathbf{X})}=\\frac{p(\\mathbf{w},\\mathbf{X})}{\\sum_{\\mathbf{w}} p(\\mathbf{w},\\mathbf{X})}\\tag{1}$$もしくは$W$が連続変数の場合、$$p(\\mathbf{w}|\\mathbf{X})=\\frac{p(\\mathbf{w},\\mathbf{X})}{p(\\mathbf{X})}=\\frac{p(\\mathbf{w},\\mathbf{X})}{\\int_{\\mathbf{w}} p(\\mathbf{w},\\mathbf{X})d\\mathbf{w}}\\tag{2}$$を計算することで$p(\\mathbf{w}|\\mathbf{X})$を推論することができること。\n  の３点です。\nしかし、前節で例示したような簡単な例を除いて、現実のほとんどの問題では、(1)式や(2)式の周辺分布（つまり和や積分の部分）は計算量が膨大であったり積分が解析的に不可能であり、厳密に計算できません。そこでこの周辺分布の計算を近似的にかつ現実的な時間内で計算する手法としてサンプリングや変分近似の手法が考案されてきました。ここではその１つである変分近似の手法について解説します。\n※ 以降では確率変数が連続変数の場合に限って説明をしていきますが離散変数の場合でも同様の議論が可能です。\n変分近似 #  我々は$p(\\mathbf{w}|\\mathbf{X})$を求めたいわけですが、この未知の確率分布がなんらかシンプルな関数$q(\\mathbf{w})$で表現できないかと考えます。この$q(\\mathbf{w})$を本来求めたい確率分布$p(\\mathbf{w}|\\mathbf{X})$に近づけていくことで$p(\\mathbf{w}|\\mathbf{X})$を近似的に求めてやろうという方法が変分近似です。\nここで$p(\\mathbf{w}|\\mathbf{X})$と近似関数$q(\\mathbf{w})$の類似度合いの指標としてKLダイバージェンスを採用すると変分近似は、 $$ q_{opt.}(\\mathbf{w})=\\underset{q}{\\operatorname{argmax}} \\operatorname{KL}(q(\\mathbf{w})||p(\\mathbf{w}|\\mathbf{X}))$$ の最適化問題として定式化できます。\nしかしKLダイバージェンスに未知の関数である$p(\\mathbf{w}|\\mathbf{X})$が入っているため、このままでは$q_{opt.}$を求めることはできません。そこでこのKLダイバージェンスの最小化問題を、数学的なトリックを使って別の計算可能な量の最大化問題に書き換えることで間接的にKLダイバージェンスを最小化する関数を求めることを行います。ではどのようにするのでしょうか？\nELBO #  ここで対数周辺尤度$\\ln{p(\\mathbf{X})}$を以下のように書き換えることができることに着目します。 $$ \\begin{align} \\ln{p(\\mathbf{X})} \u0026amp; = \\ln{p(\\mathbf{X})} \\int_{\\mathbf{w}} q(\\mathbf{w}) d\\mathbf{w}\\newline \u0026amp; = \\int_{\\mathbf{w}} q(\\mathbf{w}) \\ln\\frac{p(\\mathbf{X}, \\mathbf{w})}{p(\\mathbf{w} \\vert \\mathbf{X})} d\\mathbf{w}\\newline \u0026amp; = \\int_{\\mathbf{w}} q(\\mathbf{w}) \\ln \\frac{p(\\mathbf{X}, \\mathbf{w})~q(\\mathbf{w})}{p(\\mathbf{w} \\vert \\mathbf{X}) ~q(\\mathbf{w})} d\\mathbf{w}\\newline \u0026amp; = \\int_{\\mathbf{w}} q(\\mathbf{w}) \\ln \\frac{p(\\mathbf{X}, \\mathbf{w})}{q(\\mathbf{w})} d\\mathbf{w} + \\int_{\\mathbf{w}} q(\\mathbf{w}) \\ln \\frac{q(\\mathbf{w})}{p(\\mathbf{w} \\vert \\mathbf{X})} d\\mathbf{w}\\newline \u0026amp; = \\mathcal{L}(\\mathbf{X}) + \\operatorname{KL}(q\\vert \\vert p) \\end{align} $$ ここで１行目は $$ \\int_{\\mathbf{w}} q(\\mathbf{w}) d\\mathbf{w} = 1 $$ を使っています。\nここで$\\mathcal{L}(\\mathbf{X})$は、我々が仮定する関数$q(\\mathbf{w})$と確率モデル$p(\\mathbf{X}, \\mathbf{w})$から構成されているため計算が可能であることに注意してください。周辺尤度$p(\\mathbf{X})$は確率モデルと観測データが与えられれば一意的に値が決まる量なので、上の式はこの$\\mathcal{L}(\\mathbf{X})$を最大化する$q(\\mathbf{w})$を求めれば、それが自動的にKLダイバージェンスを最小化する$q(\\mathbf{w})$を求めていることになることを示しています。つまり未知の関数を含むKLダイバージェンスを直接最小化できなくても、代わりに$\\mathcal{L}(\\mathbf{X})$を最大化すればその目的が達成できるのです！\nこの$\\mathcal{L}(\\mathbf{X})$をELBO(Evidence Lower BOund)と呼びます。\nここで$q(\\mathbf{w})$をなんらかパラメータ$\\boldsymbol{\\alpha}$で特徴づけられる関数を仮定しているとすると、ELBO$\\mathcal{L}(\\mathbf{X})$の最大化、言い換えて$-\\mathcal{L}(\\mathbf{X})$の最小化はパラメータに対する偏微分$\\frac{\\partial \\mathcal{L}}{\\partial \\boldsymbol{\\alpha}}$を求めて勾配降下法で最適化計算を行っていくことができことになります。\n以上、変分近似について解説してきました。要点は、\n 事後確率$p(\\mathbf{w}|\\mathbf{X})$をパラメータ$\\boldsymbol{\\alpha}$で特徴づけられる関数（変分関数）$q(\\mathbf{w})$で表現する。 求めたい事後確率分布に変分関数を似せる（つまりKLダイバージェンスを最小化する）ことで事後分布を近似的に求める。 ただしKLダイバージェンスを直接計算できないので、代わりにELBOを最大化することで最適な変分関数$q_{opt.}(\\mathbf{w})$を求める。 ELBOの最大化は勾配降下法を用いて行う。 ということになります。  次節以降でPyroで変分近似を行う例を具体的に示していきます。\n"});})();